#! /usr/bin/env python3

# prereqs:
# config file: specified in ES_CONFIG_PATH
# mapping file: 
# vos.analysis.lib.tstos:

from __future__ import print_function

import sys, os, time, re, stat
import hashlib, json, glob

try:
    from configparser import SafeConfigParser, NoSectionError, NoOptionError
except: 
    from ConfigParser import SafeConfigParser, NoSectionError, NoOptionError
    
from optparse import OptionParser, make_option
from elasticsearch import VERSION, Elasticsearch, helpers, exceptions as es_excs
from urllib3 import exceptions as ul_excs, Timeout
from datetime import datetime
import tarfile
from vos.analysis.lib import tstos

from pprint import pprint

PBENCH_VERSION = '0.33'
_VERSION_ = "0.0.0.2"
_NAME_    = "index-pbench"
# _index_   = "pbench.pbench-0.33"

###########################################################################
# Fetch the mapping file for pbench metadata.
# It is passed to the index creation routine.
def fetch_mapping(mapping_fn):
    with open(mapping_fn, "r") as mappingfp:
        try:
            mapping = json.load(mappingfp)
        except ValueError as err:
            print("%s: %s" % (mapping_fn, err), file=sys.stderr)
            sys.exit(1)
    keys = list(mapping.keys())
    if len(keys) != 1:
        print("Invalid mapping file: %s" % mapping_fn, file=sys.stderr)
        sys.exit(1)
    return keys[0], mapping

###########################################################################
# this is cribbed from the vos sosreport index stuff and should be
# made generic and imported.
_read_timeout = 30

def get_hosts(config):
    """
    Return list of dicts (a single dict for now) -
    that's what ES is expecting.
    """
    try:
        URL = config.get('Server', 'server')
    except NoSectionError:
        print("Need a [Server] section with host and port defined in %s"
              " configuration file" % (" ".join(config.__files__)),
                file=sys.stderr)
        return None
    except NoOptionError:
        host = config.get('Server', 'host')
        port = config.get('Server', 'port')
    else:
        host, port = URL.rsplit(':', 1)
    timeoutobj = Timeout(total=1200, connect=10, read=_read_timeout)
    return [dict(host=host, port=port, timeout=timeoutobj),]

_op_type = "create"

def es_index(es, actions, dbg=0):
    """
    Now do the indexing specified by the actions.
    """
    delay = _read_timeout
    tries = 20

    beg, end = time.time(), None
    start = beg
    if dbg > 0:
        print("\tbulk index (beg ts: %s) ..." % tstos(beg))
        sys.stdout.flush()
    while True:
        try:
            res = helpers.bulk_index(es, actions)
        except es_excs.ConnectionError as err:
                end = time.time()
                if isinstance(err.info, ul_excs.ReadTimeoutError):
                    tries -= 1
                    if tries > 0:
                        print("\t\tWARNING (end ts: %s, duration: %.2fs):"
                              " read timeout, delaying %d seconds before"
                              " retrying (%d attempts remaining)..." % (
                                  tstos(end), end - beg, delay, tries),
                                  file=sys.stderr)
                        time.sleep(delay)
                        delay *= 2
                        beg, end = time.time(), None
                        print("\t\tWARNING (beg ts: %s): retrying..." % (
                            tstos(beg)), file=sys.stderr)
                        continue
                print("\tERROR(%s) (end ts: %s, duration: %.2fs): %s" % (
                    _NAME_, tstos(end), end - start, err), file=sys.stderr)
                return 1
        except Exception as err:
            end = time.time()
            print("\tERROR(%s) (end ts: %s, duration: %.2fs): %s" % (
                _NAME_, tstos(end), end - start, err), file=sys.stderr)
            return 1
        else:
            end = time.time()
            successes = res[0]
            duplicates = 0
            errors = 0
            len_res1 = len(res[1])
            for idx, ires in enumerate(res[1]):
                sts = ires[_op_type]['status']
                if sts not in (200, 201):
                    if _op_type == 'create' and sts == 409:
                        duplicates += 1
                    else:
                        print("\t\tERROR (%d of %d): %r" % (
                            idx, len_res1, ires[_op_type]['error']),
                            file=sys.stderr)
                        errors += 1
                else:
                    successes += 1
            if dbg > 0 or errors > 0:
                print("\tdone (end ts: %s, duration: %.2fs,"
                    " success: %d, duplicates: %d, errors: %d)" % (
                        tstos(end), end - start, successes, duplicates,
                        errors))
                sys.stdout.flush()
            if errors > 0:
                if successes > 0:
                    modifier = "some "
                else:
                    modifier = ""
                    print("\tERROR(%s) %serrors encountered during indexing" % (
                        _NAME_, modifier), file=sys.stderr)
                    return 1
            break
    return 0

###########################################################################
# get metadata from metadata.log
# metadata.log is in the format expected by configparser,
# so we just get and return a configparser object.
def get_mdconfig(mdf):

    mdfconfig = SafeConfigParser()
    # XXX - review
    # ^%*&%(&% encoding: the read() returns bytes but configparser
    # wants a string somewhere deep inside and I don't know how to
    # tell it. So read it as bytes and convert it to string assuming ascii
    # encoding - and have configparser read the config from the string.
    mdfconfig.read_string(str(mdf.read(), 'ascii'))
    return mdfconfig

###########################################################################
# old tarballs do not contain a metadata.log, so we are
# left to fend for ourselves. We troll through the pbench.log
# file and get beginning and ending timestamps: unfortunately, they
# are in local time, so we assume they are run on machines in BOS
# or RDU, which use EST/EDT/

def convert_to_utc(t):
    """ convert it to UTC, assuming it is EST/EDT"""

    import pytz
    local = pytz.timezone("America/New_York")
    local_dt = local.localize(t)
    # return it as UTC
    return local_dt.astimezone(pytz.utc)

def utc_ts(s):
    from datetime import datetime

    # parse string of form '[debug][<TS>].*\n'
    ifmt = "%Y%m%d_%H:%M:%S.%f"
    ts = s.split(']')[1].replace('[', '')
    df = ts.split('.')
    # python can only do microseconds
    ts = "%s.%.6s" % (df[0], df[1])
    t = datetime.strptime(ts, ifmt)
    t = convert_to_utc(t)
    ofmt =  "%Y-%m-%d_%H:%M:%S.%f"
    return t.strftime(ofmt)

def get_start_end_time_utc(pbf):

    start = utc_ts(str(pbf.readline(), 'ascii'))
    pbf.seek(-1024, 2)
    end = utc_ts(str(pbf.readlines()[-1], 'ascii'))
    return (start, end)

# 
def get_pb(dirname):
    member_name = "%s/pbench.log" % (dirname)
    pblog = tb.getmember(member_name)
    d = get_metadata_pb(tb.extractfile(member_name))

def get_metadata_pb(pbf):
    # no metadata.log file :-(
    # grovel through pbench.log and try to extract as much info as possible
    d = {}
    runtimes = get_start_end_time_utc(pbf)
    d['start_run'] = runtimes[0]
    d['end_run'] = runtimes[1]
    return d

###########################################################################
# generic metadata routines

class UnsupportedTarballFormat(Exception):
    pass

def mk_pbench_metadata(fname):

    tb = tarfile.open(fname)
    dirname=os.path.basename(fname).strip('.tar.xz')
    d = {}
    try:
        member_name = "%s/metadata.log" % (dirname)
        mdlog = tb.getmember(member_name)
        mdconf = get_mdconfig(tb.extractfile(member_name))
        try:
            d['pbench-rpm-version'] = mdconf.get("pbench", "rpm-version")
        except:
            d['pbench-rpm-version'] = "Unknown"
    except:
        raise UnsupportedTarballFormat
    return d

def get_run_metadata(mdconf):
    try:
        d = {}
        d.update(mdconf.items('run'))
        d.update(mdconf.items('pbench'))
        del d['rpm-version']
        return d
    except:
        return {}
    
def mk_run_metadata(fname):
    tb = tarfile.open(fname)
    dirname=os.path.basename(fname).strip('.tar.xz')
    d = {}
    try:
        member_name = "%s/metadata.log" % (dirname)
        mdlog = tb.getmember(member_name)
        mdconf = get_mdconfig(tb.extractfile(member_name))
        d = get_run_metadata(mdconf)
    except:
        # no metadata.log
        pass

    # from pprint import pprint; pprint(d)
    return d

def get_tool_info(mdconf):
    try:
        d = []
        # from pprint import pprint; pprint(mdconf.get("tools", "hosts"))
        
        for host in mdconf.get("tools", "hosts").split(' '):
            # from pprint import pprint; pprint(host)
            tools = {}
            tools.update(mdconf.items("tools/%s" % (host)))
            tools['host'] = host
            d.append(tools)
        return d
    except:
        return []
        
def mk_tool_info(fname):
    """Return a dict containing tool info (local and remote)"""
    tb = tarfile.open(fname)
    dirname = os.path.basename(fname).strip('.tar.xz')
    l = []
    try:
        member_name = "%s/metadata.log" % (dirname)
        mdlog = tb.getmember(member_name)
        mdconf = get_mdconfig(tb.extractfile(member_name))
        l = get_tool_info(mdconf)
    except:
        pass
    
    return l

def mk_toc(fname):
    """Return a dict with a "toc" entry"""
    tb = tarfile.open(fname)
    d = {"toc": tb.getnames()}
    return d

def mk_metadata(fname, md5sum):
    """Return a dict with metadata about a tarball"""
    tb = tarfile.open(fname)
    mtime = datetime.fromtimestamp(os.stat(fname)[stat.ST_MTIME])
        
    mddict = {'generated-by': _NAME_,
              'generated-by-version': _VERSION_,
              'file-date': mtime.strftime("%Y-%m-%d"),
              'file-name': fname,
              'md5': md5sum
    }
    return mddict

def mk_source(hostname, name, md5sum):
    # a dict containing:
    #   metadata about the tarball,
    #   pbench metadata
    #   run metadata
    #   tool info
    #   tarball toc
    
    rec = {}
    rec['_metadata'] = mk_metadata(name, md5sum)
    rec['pbench'] = mk_pbench_metadata(name)
    rec['run'] = mk_run_metadata(name)
    rec['tools'] = mk_tool_info(name)
    rec['table-of-contents'] = mk_toc(name)
    return rec

def get_md5(name):
    """Open the MD5 file and read the MD5 sum from it."""
    return open("%s.md5" % (name)).read().split()[0]

def mk_action(hostname, tbname, tname, options):

    """Extract metadata from the named tarball and create an indexing
       action out of them.  We don't index the data (yet).
       There are two kinds of metadata: what goes into _source[_metadata]
       is metadata about the tarball itself - not things that are *part* of
       the tarball: its name, size, md5, mtime.
       Metadata about the run are *data* to be indexed.
    """

    # make a simple action for indexing
    md5sum = get_md5(tbname)
    source = mk_source(hostname, tbname, md5sum)
    if options.unittest:
        ts = datetime.strptime("1900-01-01T00:00:00", "%Y-%m-%dT%H:%M:%S")
    else:
        ts = datetime.now()
    action = {
        "_op_type": "create",
        "_index": tname,
        "_type" : "pbench-run",
        "_id"   : md5sum,
        # XXX
        "_timestamp" : ts,
        "_source"    : source,
    }
    return action

def main(options, args):
    config=SafeConfigParser()
    try:
        cfg_name = options.cfg_name
    except:
        cfg_name = os.environ.get("ES_CONFIG_PATH")

    if not cfg_name:
        print("No config file specified: set ES_CONFIG_PATH env variable or use --config <file> on the command line", file=sys.stderr)
        exit(1)
    config.read(cfg_name)
    INDEX_PREFIX = config.get('Settings', 'index_prefix')
    INDEX_VERSION = config.get('Settings', 'index_version')
    NUMBER_OF_SHARDS = config.get('Settings', 'number_of_shards')
    NUMBER_OF_REPLICAS = config.get('Settings', 'number_of_replicas')
    settings = dict(
        number_of_shards=NUMBER_OF_SHARDS,
        number_of_replicas=NUMBER_OF_REPLICAS,
        codec=dict(
            bloom=dict(
                load='false')),
        gateway=dict(
            local=dict(
                sync='1m')),
        merge=dict(
            scheduler=dict(
                max_thread_count=1)),
        translog=dict(
            flush_threshold_size='1g'),
    )

    # where to find the mappings
    LIBDIR = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(sys.argv[0]))), 'lib', 'mappings')

    pbench_mappings = {}
    pbench_settings = settings
    for mapping_fn in glob.iglob(os.path.join(LIBDIR, "*.json")):
        key, mapping = fetch_mapping(mapping_fn)
        pbench_mappings[key] = mapping

    # The API body for the create() contains a dictionary with the settings and
    # the mappings.
    pbench_body = dict(
        template='%s.pbench-*' % (INDEX_PREFIX,),
        settings=pbench_settings,
        mappings=pbench_mappings)

    hosts = get_hosts(config)
    es = Elasticsearch(hosts, max_retries=0)

    # create the index with the indicated mappings
    tname = "%s.pbench-%s-%s" % (INDEX_PREFIX, PBENCH_VERSION, INDEX_VERSION)
    try:
        res = es.indices.put_template(name=tname, body=pbench_body)
    except Exception as err:
        print(repr(err), file=sys.stderr)
        sys.exit(1)

    # prepare the actions
    hostname = os.path.basename(os.path.dirname(args[0]))
    tbname = args[0]
    actions = []
    try:
        actions.append(mk_action(hostname, tbname, tname, options))
    except UnsupportedTarballFormat:
        # bail
        return 2 

    if options.unittest:
        pprint(actions)
        return 0
    
    return es_index(es, actions)

prog_options = [
    make_option("-C", "--config", dest="cfg_name", help="Specify config file"),
    make_option("-U", "--unittest", action="store_true", dest="unittest", help="Run in unittest mode")
]

if __name__ == '__main__':
    parser = OptionParser("Usage: index-pbench [--config <path-to-config-file>] <path-to-tarball>")
    for o in prog_options:
        parser.add_option(o)
        
    (options, args) = parser.parse_args()
    
    status = main(options, args)
    sys.exit(status)
