#!/bin/bash
export LANG=C
export LC_ALL=C
_tdir=$(dirname $(readlink -f ${0}))

_testroot=/var/tmp/pbench-test-utils
mkdir -p ${_testroot}
if [[ ! -d ${_testroot} ]]; then
    echo "ERROR: failed to create test root directory, \"${_testroot}\"" >&2
    exit 1
fi
rm -rf ${_testroot}/*
if [[ ${?} -gt 0 ]]; then
    echo "ERROR: failed to empty test root directory, \"${_testroot}\"" >&2
    exit 1
fi
export _testout=${_testroot}/output.txt
export _testlog=${_testroot}/test-execution.log
export _testdir=${_testroot}/pbench

# Copy util-scripts execution environment to _testroot
_testopt=${_testroot}/opt/pbench-agent
res=0
mkdir -p ${_testopt}/config ${_testopt}/util-scripts ${_testopt}/tool-scripts ${_testopt}/lib ${_testopt}/unittest-scripts ${_testopt}/common/lib
let res=res+${?}
cp -L ${_tdir}/../base ${_testopt}/
let res=res+${?}
cp -rL ${_tdir}/../config/* ${_testopt}/config/
let res=res+${?}
cp -a $_tdir/../../lib/* $_testopt/common/lib/
let res=res+${?}
cp -a ${_tdir}/{getconf.py,require-rpm,pbench-*} ${_testopt}/util-scripts/
let res=res+${?}
scripts="${_tdir}/../tool-scripts/*"
for script in ${scripts}; do
    if [[ "${script}" == *README ]]; then
        # Ignore all README files
        continue
    fi
    if [[ -d "${script}" ]]; then
        # Ignore any sub-directories
        continue
    fi
    cp -L ${script} ${_testopt}/tool-scripts/
    let res=res+${?}
done
mkdir ${_testopt}/tool-scripts/datalog ${_testopt}/tool-scripts/postprocess
let res=res+${?}
cp -L ${_tdir}/../tool-scripts/datalog/*-datalog ${_testopt}/tool-scripts/datalog/
let res=res+${?}
cp -L ${_tdir}/../tool-scripts/datalog/*-convert ${_testopt}/tool-scripts/datalog/
let res=res+${?}
cp -L ${_tdir}/../tool-scripts/postprocess/*-postprocess ${_testopt}/tool-scripts/postprocess/
let res=res+${?}
cp ${_tdir}/../tool-scripts/postprocess/*-postprocess-cdm ${_testopt}/tool-scripts/postprocess/
let res=res+${?}
cp -rL ${_tdir}/../lib/* ${_testopt}/lib/
let res=res+${?}
cp -rL ${_tdir}/test-bin/* ${_testopt}/unittest-scripts/
let res=res+${?}

if [[ $res -ne 0 ]]; then
    echo "ERROR: failed to construct unittest execution directory hierarchy" \
         "under, \"${_testroot}\"" >&2
    exit 1
fi

function remove_path {
    # PATH (${2}) => /bin:/opt/a dir/bin:/sbin
    WORK=:${2}:
    # WORK => :/bin:/opt/a dir/bin:/sbin:
    REMOVE=${1}
    WORK=${WORK/:${REMOVE}:/:}
    # WORK => :/bin:/sbin:
    WORK=${WORK%:}
    WORK=${WORK#:}
    #PATH=${WORK}
    # PATH => /bin:/sbin
    echo ${WORK}
}
PATH=$(remove_path /opt/pbench-agent/bench-scripts ${PATH})
PATH=$(remove_path /opt/pbench-agent/util-scripts ${PATH})
# Allows us to intercept scp, ssh, rsync, etc.
export PATH=${_testopt}/unittest-scripts:${_testopt}/util-scripts:${_testopt}/tool-scripts:${PATH}
export PYTHONPATH=${_testopt}/common/lib:${PYTHONPATH}

# Fixed timestamp output
export _PBENCH_UNIT_TESTS=1

res=0

function _run {
    local sts

    tname=${1}
    shift
    tscrpt=${1}
    shift

    pushd ${_testdir} > /dev/null 2>&1
    if [[ ${?} -ne 0 ]]; then
        exit 1
    fi

    echo "${tname} ${tscrpt} ${@}"
    echo "+++ Running ${tname} ${tscrpt} ${@}" >> ${_testout}

    ${tscrpt} ${@} >> ${_testout} 2>&1
    sts=${?}

    popd > /dev/null 2>&1
    if [[ ${?} -ne 0 ]]; then
        exit 1
    fi

    echo "--- Finished $tname ${tscrpt} (status=${sts})" >> ${_testout}
    return ${sts}
}

function _save_tree {
    # Save state of the tree
    echo "+++ pbench tree state" >> ${_testout}
    find ${_testdir} 2> /dev/null | sort >> ${_testout}

    for x in $(find "${_testdir}/tools"-* -type f 2> /dev/null | sort); do
        echo "=== ${x}:"
        cat ${x}
    done >> ${_testout}

    for x in $(find "${_testdir}/tmp" -type f 2> /dev/null | sort); do
        echo "=== ${x}:"
        cat ${x}
    done >> ${_testout}
    echo "--- pbench tree state" >> ${_testout}
}

function _dump_logs {
    # Dump the state of any generated script logs
    if [[ -f ${_testdir}/pbench.log ]]; then
        echo "+++ pbench.log file contents" >> ${_testout}
        cat ${_testdir}/pbench.log >> ${_testout} 2>&1
        echo "--- pbench.log file contents" >> ${_testout}
    fi
    for mdlog in ${_testdir}/*/metadata.log; do
        if [[ -f ${mdlog} ]]; then
            mddir=$(basename $(dirname "${mdlog}"))
            if [[ "${mddir}" == "tmp" ]]; then
                continue
            fi
            echo "+++ ${mddir}/metadata.log file contents" >> ${_testout}
            cat ${_testdir}/${mddir}/metadata.log >> ${_testout} 2>&1
            echo "--- ${mddir}/metadata.log file contents" >> ${_testout}
        fi
    done
    local bm_run_dir="$(basename "${benchmark_run_dir}")"
    for actionlog in $(cd ${_testdir}; find "${bm_run_dir}" \( -name 'stop.log' -o -name 'postprocess.log' \) 2> /dev/null | sort); do
        echo "+++ ${actionlog} file contents" >> ${_testout}
        cat ${_testdir}/${actionlog} >> ${_testout} 2>&1
        echo "--- ${actionlog} file contents" >> ${_testout}
    done
    if [[ -f ${_testlog} ]]; then
        echo "+++ test-execution.log file contents" >> ${_testout}
        cat ${_testlog} >> ${_testout} 2>&1
        echo "--- test-execution.log file contents" >> ${_testout}
        rm -f ${_testlog}
    fi
}

function _verify_output {
    local sts tname tscrpt expected_status
    sts=${1}
    tname=${2}
    tscrpt=${3}
    expected_status=${4:-0}
    # fix up any pids that have snuck into the output.
    sed -e 's;tmp/\([a-z-]*\)\.[0-9][0-9]*;tmp/\1.NNNNN;g' \
        -e 's;raw_size = [0-9][0-9]*;raw_size = #####;g' \
        -e 's;tar up [0-9][0-9]* bytes;tar up ##### bytes;g' ${_testout} |
        diff -c ${_tdir}/gold/${tscrpt}/${tname}.txt -
    if [[ ${?} -gt 0 ]]; then
        echo "FAIL - ${tname}"
        mv ${_testout} ${_testroot}/${tname}_output.txt
        sts=1
    else
        if [[ ${sts} -eq 0 ]]; then
            echo "PASS - ${tname}"
            rm ${_testout}
        elif [[ ${sts} -eq ${expected_status} ]]; then
            echo "PASS - ${tname} exited with expected status: ${sts}"
            rm ${_testout}
            sts=0
        else
            echo "FAIL - ${tname}: PASS output but execution returned non-zero exit status"
        fi
    fi
    return ${sts}
}

function _setup_state {
    local tool
    local tst
    tst=${1}
    tool=${2}

    sed "s;/opt/pbench-agent;${_testopt};" ${_testopt}/config/pbench-agent.cfg.example > ${_testopt}/config/pbench-agent.cfg
    if [[ ${?} -ne 0 ]]; then
        echo "ERROR: failed to create default pbench-agent.cfg" >&2
        exit 1
    fi
    export _PBENCH_AGENT_CONFIG=${_testopt}/config/pbench-agent.cfg

    mkdir ${_testdir}
    if [[ ${?} -ne 0 ]]; then
        echo "ERROR: failed to create test pbench directory, \"${_testdir}\"" >&2
        exit 1
    fi
    if [[ ! -z "${tool}" && ! -z "${tst}" ]]; then
        if [[ -e ${_tdir}/configs/${tool}/${tst}/pbench-agent.cfg.frag ]]; then
            printf -- "\n" >> ${_PBENCH_AGENT_CONFIG}
            cat ${_tdir}/configs/${tool}/${tst}/pbench-agent.cfg.frag >> ${_PBENCH_AGENT_CONFIG}
            if [[ ${?} -ne 0 ]]; then
                echo "ERROR: failed to setup pbench-agent.cfg file" >&2
                exit 1
            fi
        fi
        if [[ -d ${_tdir}/samples/${tool}/${tst} ]]; then
            cp -r ${_tdir}/samples/${tool}/${tst}/* ${_testroot}
            if [[ ${?} -ne 0 ]]; then
                echo "ERROR: failed to setup ${tool}/${tst} samples" >&2
                exit 1
            fi
        fi
    fi

    export pbench_install_dir=${_testopt}
    export pbench_run=${_testdir}
    export pbench_log=${_testdir}/pbench.log
    export pbench_bspp_dir=${_testopt}/bench-scripts/postprocess
    export pbench_lib_dir=${_testopt}/lib
    export benchmark="fake-bm"
    export benchmark_bin=${_testopt}/unittest-scripts/bm

    # Discover the "benchmark_run_dir"
    bm_run_dir="$(ls -1 ${_testdir} 2>/dev/null | grep -vE 'tmp|tools-.+|tool-triggers|tools\.default' 2>/dev/null)"
    if [[ -z "${bm_run_dir}" ]]; then
        bm_run_dir="mock-run"
    fi
    export benchmark_run_dir=${_testdir}/${bm_run_dir}
}

function _reset_state {
    rm ${_testopt}/config/pbench-agent.cfg
    unset _PBENCH_AGENT_CONFIG

    rm -rf ${_testdir}
    if [[ -d ${_testdir} ]]; then
        echo "ERROR: unable to remove pbench hierarchy" >&2
        exit 1
    fi

    unset benchmark_run_dir
    unset benchmark_bin
    unset benchmark
    unset pbench_lib_dir
    unset pbench_bspp_dir
    unset pbench_log
    unset pbench_run
    unset pbench_install_dir
}

let errs=0

declare -A tools=(
    [test-00]="pbench-register-tool"
    [test-01]="pbench-metadata-log"
    [test-02]="pbench-metadata-log"
    [test-03]="pbench-metadata-log"
    [test-04]="pbench-metadata-log"
    [test-05]="pbench-stop-tools"
    [test-06]="pbench-stop-tools"
    [test-07]="pbench-stop-tools"
    [test-08]="pbench-stop-tools"
    [test-09]="pbench-stop-tools"
    [test-10]="pbench-stop-tools"
    [test-11]="pbench-register-tool-set"
    [test-11.1]="pbench-register-tool-set"
    [test-11.2]="pbench-register-tool-set"
    [test-11.3]="pbench-register-tool-set"
    [test-11.4]="pbench-register-tool-set"
    [test-11.5]="pbench-register-tool-set"
    [test-11.6]="pbench-register-tool-set"
    [test-11.7]="pbench-register-tool-set"
    [test-11.8]="pbench-register-tool-set"
    [test-11.9]="pbench-register-tool-set"
    [test-11.10]="pbench-register-tool-set"
    [test-11.11]="pbench-register-tool-set"
    [test-11.12]="pbench-register-tool-set"
    [test-11.13]="pbench-register-tool-set"
    [test-11.14]="pbench-register-tool-set"
    [test-12]="pbench-clear-tools"
    [test-13]="pbench-postprocess-tools"
    [test-14]="pbench-agent-config-activate"
    [test-15]="pbench-register-tool-trigger"
    [test-16]="pbench-list-triggers"
    [test-17]="pbench-list-triggers"
    [test-18]="pbench-list-triggers"
    [test-19]="test-tool-trigger"
    [test-20]="pbench-postprocess-tools"
    [test-21]="pbench-clear-tools"
    [test-22]="pbench-metadata-log"
    [test-23]="pbench-collect-sysinfo"
    [test-24]="pbench-collect-sysinfo"
    [test-25]="pbench-collect-sysinfo"
    [test-26]="pbench-collect-sysinfo"
    [test-27]="pbench-collect-sysinfo"
    [test-28]="pbench-collect-sysinfo"
    [test-29]="pbench-collect-sysinfo"
    [test-30]="pbench-collect-sysinfo"
    [test-31]="pbench-copy-results"
    [test-32]="pbench-copy-results"
    [test-33]="pbench-move-results"
    [test-34]="pbench-move-results"
    [test-35]="pbench-register-tool-trigger"
    [test-36]="pbench-register-tool-trigger"
    [test-37]="pbench-move-results"
    [test-38]="pbench-move-results"
    [test-39]="pbench-copy-results"
    [test-40]="pbench-copy-results"
    [test-41]="pbench-copy-results"
    [test-42]="pbench-register-tool"
    [test-43]="pbench-register-tool"
    [test-44]="pbench-register-tool"
    [test-45]="pbench-register-tool"
    [test-46]="pbench-register-tool"
    [test-47]="pbench-register-tool"
    [test-48]="test-add-metalog-%-option"
    [test-49]="pbench-copy-results"
    [test-50]="test-pbench-metadata-log"
)

declare -A options=(
    [test-00]="--name=mpstat --group=default -- --interval=10"
    [test-01]="--dir=${_testdir}/mock-run beg"
    [test-02]="--dir=${_testdir}/mock-run beg"
    [test-03]="--dir=${_testdir}/mock-run beg"
    [test-04]="--dir=${_testdir}/mock-run beg"
    [test-05]="--dir=${_testdir}/mock-run/mock-iteration/mock-sample"
    [test-06]="--dir=${_testdir}/mock-run/mock-iteration/mock-sample"
    [test-07]="--dir=${_testdir}/mock-run/mock-iteration/mock-sample"
    [test-08]="--dir=${_testdir}/mock-run/mock-iteration/mock-sample"
    [test-09]="--dir=${_testdir}/mock-run/mock-iteration/mock-sample"
    [test-10]="--dir=${_testdir}/mock-run/mock-iteration/mock-sample"
    # fubar is assumed to *NOT* exist
    [test-11]="--remote=fubar"
    [test-11.2]="--interval=10"
    # verify one remote
    [test-11.4]="--remotes=one.example.com"
    # verify multiple remotes
    [test-11.5]="--remotes=a.example.com,b.example.com,c.example.com"
    # verify no remotes with a label (local)
    [test-11.6]="--labels=labelNO"
    # verify one remote (default) with two labels
    [test-11.7]="--labels=labelG,labelB"
    # verify two remotes with one label
    [test-11.8]="--remotes=one.example.com,two.example.com --labels=labelOne"
    # verify three remotes with three labels
    [test-11.9]="--remotes=one.example.com,two.example.com,three.example.com --labels=labelOne,labelTwo,labelThree"
    # verify --toolset option other than "default"
    [test-11.10]="--toolset=other"
    # verify --toolset option that does not exist
    [test-11.11]="--toolset=doesntexist"
    # verify --group option works along side --no-install
    [test-11.12]="--group=other --no-install"
    [test-11.13]="--help"
    [test-13]="--dir=${_testdir}/mock-run/mock-iteration/mock-sample --group=default"
    [test-14]="${_testdir}/tmp/pbench-agent.cfg"
    [test-15]="--group=default --start-trigger=\"START DEFAULT\" --stop-trigger=\"STOP DEFAULT\""
    [test-17]="--group=default"
    [test-18]="--group=foo"
    [test-20]="--dir=${_testdir}/mock-run/mock-iteration/mock-sample --group=default"
    [test-21]="--remote=fubar2"
    [test-22]="--dir=${_testdir}/mock-run end"
    [test-23]="--help"
    [test-24]="--options"
    [test-25]="--check --sysinfo=all"
    [test-26]="--check --sysinfo=none"
    [test-27]="--check --sysinfo=default"
    [test-28]="--check --sysinfo=block,libvirt,kernel_config,sos,topology"
    [test-29]="--check --sysinfo=block,sos,bad,topology"
    [test-30]="--check --sysinfo=libvirt,default,kernel_config,all,topology,none"
    [test-31]="--prefix=foo/bar --user=ndk"
    [test-32]="--help"
    [test-34]="--help"
    [test-35]="--group=default --start-trigger=\"START:DEFAULT\" --stop-trigger=\"STOP DEFAULT\""
    [test-36]="--group=default --start-trigger=\"START DEFAULT\" --stop-trigger=\"STOP:DEFAULT\""
    [test-37]="--prefix="
    [test-38]="--user="
    [test-39]="--prefix=goo/tar"
    [test-40]="--user=pap"
    [test-42]="--name=vmstat --group=default --no-install -- --interval=42"
    [test-43]="--name=turbostat --no-install --remotes=one.example.com,localhost,testhost.example.com,two.example.com"
    [test-44]="--name=mpstat --no-install --remotes=@${_testdir}/tmp/doesntexist.lis"
    [test-45]="--name=mpstat --no-install --remotes=@${_testdir}/tmp/remotes.lis"
    [test-46]="--name=mpstat --no-install --remotes=@${_testdir}/tmp/remotes.lis"
    [test-47]="--name=mpstat --no-install --remotes=@${_testdir}/tmp/remotes.lis --labels=labelOne,labelTwo"
    [test-49]="--prefix=foo/bar3% --user=ndk20%"
)

declare -A expected_status=(
    [test-01]=1
    [test-05]=1
    [test-06]=1
    [test-11]=4
    [test-11.7]=1
    [test-11.8]=1
    [test-11.11]=1
    [test-12]=1
    [test-13]=2
    [test-29]=1
    [test-35]=1
    [test-36]=1
    [test-37]=1
    [test-38]=1
    [test-44]=1
    [test-46]=1
    [test-47]=1
)

declare -A pre_hooks=(
    [test-05]='mkdir -p ${_testdir}/mock-run/mock-iteration/mock-sample/tools-default/turbostat'
    [test-06]='mkdir -p ${_testdir}/mock-run/mock-iteration/mock-sample/tools-default/kvmstat'
    [test-07]='mkdir -p ${_testdir}/mock-run/mock-iteration/mock-sample/tools-default/vmstat'
    [test-08]='mkdir -p ${_testdir}/mock-run/mock-iteration/mock-sample/tools-default/numastat'
    [test-14]='rm ${_testopt}/config/pbench-agent.cfg; sed -i "s;_REPLACE_ME_;${_testopt};g" ${_testdir}/tmp/pbench-agent.cfg'
    [test-20]='mkdir -p ${_testdir}/mock-run/mock-iteration/mock-sample/tools-default/iostat; touch ${_testdir}/mock-run/mock-iteration/mock-sample/tools-default/iostat/iostat-stdout.txt'
    [test-33]='(echo "+++ setup pbench results dir time stamps"; touch --date="2019-01-01 12:00:42" ${_testdir}/pbench-user-benchmark_ndk-test-1_2019.01.01T12.00.42; touch --date="2019-01-01 12:00:43" ${_testdir}/pbench-user-benchmark_ndk-test-1_2019.01.01T12.00.43; touch --date="2019-01-01 12:00:44" ${_testdir}/pbench-user-benchmark_ndk-test-1_2019.01.01T12.00.44; echo "--- setup pbench results dir time stamps") >> ${_testout}'
    [test-45]='mkdir ${_testdir}/tmp; printf -- "# good list\none.example.com\ntwo.example.com,labelTwo\n\nthree.example.com\n" > ${_testdir}/tmp/remotes.lis'
    [test-46]='mkdir ${_testdir}/tmp; printf -- "# bad list\none.example.com\ntwo.example.com,labelTwo\n\nthree.example.com,labelThree,junk\n" > ${_testdir}/tmp/remotes.lis'
    [test-47]='mkdir ${_testdir}/tmp; printf -- "# good list with no labels\none.example.com\ntwo.example.com\nthree.example.com\n" > ${_testdir}/tmp/remotes.lis'
    [test-48]='mkdir ${_testdir}/tmp; printf -- "%s\n" "30%" > ${_testdir}/tmp/foo.txt'
)

declare -A post_hooks=(
)

tests="${*}"
if [[ -z "${tests}" ]]; then
    typeset -i len=${#tools[@]}
    len=${len}-1
    tests=$(echo ${!tools[*]} | tr ' ' '\n' | sort)
fi

for tst in ${tests}; do
    tool=${tools[${tst}]}
    opts=${options[${tst}]}
    status=${expected_status[${tst}]}
    pre_hook=${pre_hooks[${tst}]}
    post_hook=${post_hooks[${tst}]}

    _setup_state ${tst} ${tool}
    eval "${pre_hook}"
    USER=nobody _run ${tst} ${tool} ${opts}
    res=${?}
    _save_tree
    _dump_logs
    eval "${post_hook}"
    _verify_output ${res} ${tst} ${tool} ${status}
    res=${?}
    let errs=${errs}+${res}
    _reset_state
done

# Clean up opt subdirectory, and attempt to remove test directory entirely;
# if we fail, ignore it as it just means there are output files present for
# failed tests.
rm -rf ${_testroot}/opt
rmdir ${_testroot} > /dev/null 2>&1

if [[ ${errs} -gt 0 ]]; then
    sts=1
else
    sts=0
fi
exit ${sts}
