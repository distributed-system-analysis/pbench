#!/usr/bin/env python3
# -*- mode: python -*-

"""pbench-tool-meister-start

Responsible for:

   1. Starting a redis server
   2. Loading tool group data for the given tool group into the redis server
   3. Starting the tool-data-sink process
   4. Starting all the local and remote tool meisters

When complete we leave running, locally, a redis server and a tool data sink
process, and any local or remote tool meisters.

The pbench-tool-meister-stop script will take care of (gracefully) stopping
all of these processes, locally or remotely.
"""

import errno
import json
import logging
import os
import signal
import sys
import time

from distutils.spawn import find_executable
from pathlib import Path

import redis

import pbench.agent.toolmetadata as toolmetadata

from pbench.agent.tool_data_sink import main as tds_main
from pbench.agent.tool_meister import main as tm_main
from pbench.agent import PbenchAgentConfig
from pbench.common.exceptions import BadConfig


# Port number is "One Tool" in hex 0x17001
# FIXME: move to common area
redis_port = 17001

# Redis server configuration template for pbench's use
redis_conf_tmpl = """bind {hostnames}
daemonize yes
dir {tm_dir}
dbfilename pbench-redis.rdb
logfile {tm_dir}/redis.log
loglevel notice
pidfile {tm_dir}/redis_{redis_port:d}.pid
port {redis_port:d}
"""

# FIXME: this should be moved to a shared area
channel = "tool-meister-chan"

# Maximum time to wait for the Redis server to respond.
REDIS_MAX_WAIT = 60


class ToolGroup(object):
    tg_prefix = "tools-v1"

    def __init__(self, group):
        self.group = group
        _pbench_run = os.environ["pbench_run"]
        self.tg_dir = Path(_pbench_run, f"{self.tg_prefix}-{self.group}").resolve(
            strict=True
        )
        if not self.tg_dir.is_dir():
            raise Exception(
                f"bad tool group, {group}: directory {self.tg_dir} does not exist"
            )

        # __trigger__
        try:
            _trigger = (self.tg_dir / "__trigger__").read_text()
        except OSError as ex:
            if ex.errno != errno.ENOENT:
                raise
            # Ignore missing trigger file
            self.trigger = None
        else:
            if len(_trigger) == 0:
                # Ignore empty trigger file contents
                self.trigger = None
            else:
                self.trigger = _trigger

        # toolnames - Dict with tool name as the key, dictionary with host
        # names and parameters for each host
        self.toolnames = {}
        # hostnames - Dict with host name as the key, dictionary with tool
        # names and parameters for each tool
        self.hostnames = {}
        self.labels = {}
        for hdirent in os.listdir(self.tg_dir):
            if hdirent == "__trigger__":
                # Ignore handled above
                continue
            if not (self.tg_dir / hdirent).is_dir():
                # Ignore wayward non-directory files
                continue
            # We assume this directory is a hostname.
            host = hdirent
            if host not in self.hostnames:
                self.hostnames[host] = {}
            for tdirent in os.listdir(self.tg_dir / host):
                if tdirent == "__label__":
                    self.labels[host] = (
                        (self.tg_dir / host / tdirent).read_text().strip()
                    )
                    continue
                if tdirent.endswith("__noinstall__"):
                    # FIXME: ignore "noinstall" for now, tools are going to be
                    # in containers so this does not make sense going forward.
                    continue
                # This directory entry is the name of a tool.
                tool = tdirent
                tool_opts_raw_lines = (
                    (self.tg_dir / host / tool).read_text().split("\n")
                )
                tool_opts_lines = []
                for line_raw in tool_opts_raw_lines:
                    line = line_raw.strip()
                    if not line:
                        # Ignore blank lines
                        continue
                    tool_opts_lines.append(line)
                tool_opts = " ".join(tool_opts_lines)
                if tool not in self.toolnames:
                    self.toolnames[tool] = {}
                self.toolnames[tool][host] = tool_opts

    def get_tools(self, host):
        """Given a target host, return a dictionary with the list of tool names
        as keys, and the values being their options for that host.
        """
        tools = dict()
        for tool, opts in self.toolnames.items():
            try:
                host_opts = opts[host]
            except KeyError:
                # This host does not have this tool registered, ignore.
                pass
            else:
                tools[tool] = host_opts
        return tools


def wait_for_subs(chan, expected_tms, logger):
    """wait_for_subs - Wait for the data sink and the proper number of TMs to
    register, and when they are all registered, return a dictionary of the
    data sink and tool meister(s) pids.
    """
    pids = dict()
    have_ds = False
    num_tms = 0
    for payload in chan:
        try:
            json_str = payload["data"].decode("utf-8")
        except Exception:
            logger.warning("data payload in message not UTF-8, '%r'", json_str)
            continue
        logger.debug('channel payload, "%r"', json_str)
        try:
            data = json.loads(json_str)
        except json.JSONDecodeError:
            logger.warning("data payload in message not JSON, '%s'", json_str)
            continue
        # We expect the payload to look like:
        #   { "kind": "<ds|tm>",
        #     "hostname": "<hostname>",
        #     "pid": "<pid>"
        #   }
        # Where 'kind' is either 'ds' (data-sink) or 'tm' (tool-meister),
        # 'hostname' is the host name on which that entity is running, and
        # 'pid' is that entity's PID on that host.
        try:
            new_data = dict(
                kind=data["kind"], hostname=data["hostname"], pid=data["pid"]
            )
        except KeyError:
            logger.warning("unrecognized data payload in message, '%r'", data)
            continue
        else:
            if new_data["kind"] == "ds":
                pids["ds"] = new_data
                have_ds = True
            elif new_data["kind"] == "tm":
                if "tm" not in pids:
                    pids["tm"] = []
                pids["tm"].append(new_data)
                num_tms += 1
            else:
                logger.warning("unrecognized 'kind', in data payload '%r'", data)
                continue
        if have_ds and num_tms == expected_tms:
            break
    return pids


def kill_redis_server(pid_file):
    """kill_redis_server - given a redis server PID file, attempt to KILL the
    Redis server.

    Returns "1" if successfully KILL'd; "2" if it encounters an error reading
    the PID file; "3" if bad PID value; "4" if the Redis server PID does not
    exist; "5" if some kind of OSError is encountered; and "6" if some other
    exception was encountered while KILL'ing it.
    """
    try:
        raw_pid = pid_file.read_text()
    except Exception:
        # No "pid" to kill
        return 2
    else:
        try:
            pid = int(raw_pid)
        except Exception:
            # Bad pid value
            return 3
        try:
            os.kill(pid, signal.SIGKILL)
        except OSError as exc:
            if exc.errno == errno.ESRCH:
                # PID not found, ignore
                return 4
            else:
                # Some error encountered trying to KILL the process.
                return 5
        except Exception:
            # Some other error encountered trying to KILL the process.
            return 6
        else:
            # "successfully" KILL'd the give process.
            return 1


def waitpid(pid):
    """Wrapper for os.waitpid()

    Returns the exit status of the given process ID.

    Raises an exception if the final exit PID is different from the given PID.
    """
    exit_pid, _exit_status = os.waitpid(pid, 0)
    if pid != exit_pid:
        raise Exception(f"Logic bomb!  exit pid, {exit_pid}, does not match pid, {pid}")
    exit_status = os.WEXITSTATUS(_exit_status)
    return exit_status


def main(argv):
    """Main program for the tool meister start.
    """
    _prog = Path(argv[0])
    PROG = _prog.name
    logger = logging.getLogger(PROG)
    if os.environ.get("_PBENCH_TOOL_MEISTER_START_LOG_LEVEL") == "debug":
        log_level = logging.DEBUG
    else:
        log_level = logging.INFO
    logger.setLevel(log_level)
    sh = logging.StreamHandler()
    sh.setLevel(log_level)
    shf = logging.Formatter("%(message)s")
    sh.setFormatter(shf)
    logger.addHandler(sh)

    try:
        group = argv[1]
    except IndexError:
        group = "default"

    # 1. Load the tool group data given the tool group argument
    try:
        tool_group = ToolGroup(group)
    except Exception:
        logger.exception("failed to load tool group data")
        return 1

    try:
        benchmark_run_dir = os.environ["benchmark_run_dir"]
        hostname = os.environ["_pbench_hostname"]
        full_hostname = os.environ["_pbench_full_hostname"]
    except Exception:
        logger.exception("failed to fetch parameters from the environment")
        return 1
    else:
        tm_dir = Path(benchmark_run_dir, "tm")
        try:
            tm_dir.mkdir()
            os.chdir(tm_dir)
        except Exception:
            logger.exception("failed to create the local tool meister directory")
            return 1
    if not full_hostname or not hostname:
        logger.error(
            "ERROR - _pbench_hostname ('%s') and _pbench_full_hostname ('%s')"
            " environment variables are required",
            hostname,
            full_hostname,
        )
        return 1
    if os.environ.get("_PBENCH_UNIT_TESTS"):
        # FIXME: this is an artifact of the unit test environment.
        hostnames = "localhost"
    else:
        hostnames = f"localhost {full_hostname}"
    params = {"hostnames": hostnames, "tm_dir": tm_dir, "redis_port": redis_port}

    # 2. Start the Redis Server (config of port from agent config)
    #   - the Redis Server is requested to create the PID file

    # Create the Redis Server pbench-specific configuration file
    redis_conf = tm_dir / "redis.conf"
    redis_pid = tm_dir / f"redis_{redis_port:d}.pid"
    try:
        with redis_conf.open("w") as fp:
            fp.write(redis_conf_tmpl.format(**params))
    except Exception:
        logger.exception("failed to create redis server configuration")
        return 1
    # Start the Redis Server itself
    #   - FIXME: use podman to start a redis server container
    redis_srvr = "redis-server"
    redis_srvr_path = find_executable(redis_srvr)
    logger.debug("starting redis server")
    try:
        retcode = os.spawnl(os.P_WAIT, redis_srvr_path, redis_srvr, redis_conf)
    except Exception:
        logger.exception("failed to create redis server, daemonized")
        return 1
    else:
        if retcode != 0:
            logger.error(
                "failed to create redis server, daemonized; return code: %d", retcode
            )
            return 1

    try:
        timeout = time.time() + REDIS_MAX_WAIT
        started_channel = "{}-start".format(channel)
        redis_connection_state = "connecting"
        redis_server = redis.Redis(host="localhost", port=redis_port, db=0)
        pubsub = redis_server.pubsub()
        while redis_connection_state == "connecting":
            try:
                pubsub.subscribe(started_channel)
                chan = pubsub.listen()
                # Pull off first message which is an acknowledgement we have
                # successfully subscribed.
                resp = next(chan)
            except redis.exceptions.ConnectionError:
                if time.time() > timeout:
                    raise
                time.sleep(0.1)
            else:
                redis_connection_state = "connected"
    except Exception as exc:
        logger.error(
            "Unable to connect to redis server, %s:%d: %r", "localhost", redis_port, exc
        )
        return kill_redis_server(redis_pid)
    else:
        assert resp["type"] == "subscribe", f"bad type: f{resp!r}"
        assert resp["pattern"] is None, f"bad pattern: {resp!r}"
        assert (
            resp["channel"].decode("utf-8") == started_channel
        ), f"bad channel: {resp!r}"
        assert resp["data"] == 1, f"bad data: {resp!r}"

    # 2.5. Add tool metadata json to redis
    try:
        inst_dir = PbenchAgentConfig(
            os.environ["_PBENCH_AGENT_CONFIG"]
        ).pbench_install_dir
    except BadConfig as exc:
        logger.error("%s", exc)
        return 1
    except Exception as exc:
        logger.error(
            "Unexpected error encountered logging pbench agent configuration: '%s'", exc
        )
        return 1

    try:
        tm_start_path = Path(inst_dir).resolve(strict=True)
    except FileNotFoundError:
        logger.error(
            "Unable to determine proper installation directory, '%s' not found",
            inst_dir,
        )
        return 1
    except Exception as exc:
        logger.exception(
            "Unexpected error encountered resolving installation directory: '%s'", exc
        )
        return 1
    tool_metadata = toolmetadata.ToolMetadata("json", tm_start_path, logger)
    tool_metadata.loadIntoRedis(redis_server)

    # 3. Start the tool-data-sink process
    #   - leave a PID file for the tool data sink process
    tds_param_key = "tds-{}".format(group)
    tds = dict(channel=channel, benchmark_run_dir=benchmark_run_dir, group=group)
    try:
        redis_server.set(tds_param_key, json.dumps(tds, sort_keys=True))
    except Exception:
        logger.exception(
            "failed to create tool data sink parameter key in redis server"
        )
        return kill_redis_server(redis_pid)
    logger.debug("starting tool data sink")
    try:
        pid = os.fork()
        if pid == 0:
            # In the child: the main() of the Tool Data Sink module will not
            # return here since it will daemonize itself and this child pid
            # will be replaced by a new pid.
            status = tds_main(
                ["pbench-tool-data-sink", "localhost", str(redis_port), tds_param_key]
            )
            sys.exit(status)
        else:
            # In the parent: wait for the child to finish daemonizing itself.
            retcode = waitpid(pid)
            if retcode != 0:
                logger.error(
                    "failed to create pbench data sink, daemonized; return code: %d",
                    retcode,
                )
    except Exception:
        logger.exception("failed to create pbench data sink, daemonized")
        return kill_redis_server(redis_pid)

    # 4. Start all the local and remote tool meister processes
    #   - leave a PID file on each local/remote host
    failures = 0
    successes = 0
    tool_meister_cmd = _prog.parent / "tool-meister" / "pbench-tool-meister"
    # NOTE: it is assumed that the location of the pbench-tool-meister command
    # is the same on the local host as it is on any remote host.
    ssh_cmd = "ssh"
    ssh_path = find_executable(ssh_cmd)
    args = [
        ssh_cmd,
        "<host replace me>",
        f"{tool_meister_cmd}-remote",
        full_hostname,
        str(redis_port),
        "<tm param key>",
    ]
    ssh_pids = []
    for host in tool_group.hostnames.keys():
        tools = tool_group.get_tools(host)
        if host == full_hostname:
            _controller = full_hostname
        else:
            _controller = (
                "localhost" if os.environ.get("_PBENCH_UNIT_TESTS") else full_hostname
            )
        tm = dict(
            benchmark_run_dir=benchmark_run_dir,
            channel=channel,
            controller=_controller,
            group=group,
            hostname=host,
            tools=tools,
        )
        tm_param_key = "tm-{}-{}".format(group, host)
        try:
            redis_server.set(tm_param_key, json.dumps(tm, sort_keys=True))
        except Exception:
            logger.exception(
                "failed to create tool meister parameter key in redis server"
            )
            return kill_redis_server(redis_pid)
        if host == full_hostname:
            logger.debug("starting localhost tool meister")
            try:
                pid = os.fork()
                if pid == 0:
                    # In the child: the main() of the Tool Meister module will
                    # not return here since it will daemonize itself and this
                    # child pid will be replaced by a new pid.
                    status = tm_main(
                        [
                            str(tool_meister_cmd),
                            "localhost",
                            str(redis_port),
                            tm_param_key,
                        ]
                    )
                    sys.exit(status)
                else:
                    # In the parent: wait for the child to finish daemonizing
                    # itself.
                    retcode = waitpid(pid)
                    if retcode != 0:
                        logger.error(
                            "failed to create localhost tool meister,"
                            " daemonized; return code: %d",
                            retcode,
                        )
            except Exception:
                logger.exception("failed to create localhost tool meister, daemonized")
                failures += 1
            else:
                successes += 1
            continue
        args[1] = host
        args[5] = tm_param_key
        logger.debug(
            "starting remote tool meister, ssh_path=%r args=%r", ssh_path, args
        )
        try:
            pid = os.spawnv(os.P_NOWAIT, ssh_path, args)
        except Exception:
            logger.exception(
                "failed to create a tool meister instance for host %s", host
            )
            failures += 1
        else:
            ssh_pids.append((pid, host))
            successes += 1

    if failures > 0:
        return kill_redis_server(redis_pid)

    # Wait for all the SSH pids to complete.
    for pid, host in ssh_pids:
        try:
            exit_pid, _exit_status = os.waitpid(pid, 0)
        except OSError:
            failures += 1
            successes -= 1
            logger.exception(
                "failed to create a tool meister instance for host %s", host
            )
        else:
            exit_status = os.WEXITSTATUS(_exit_status)
            if pid != exit_pid:
                failures += 1
                successes -= 1
                logger.error(
                    "INTERNAL ERROR: os.waitpid(%d, 0) returned (%d, %d [%0X])",
                    pid,
                    exit_pid,
                    exit_status,
                    _exit_status,
                )
            else:
                if exit_status != 0:
                    failures += 1
                    successes -= 1
                    logger.error(
                        "failed to start tool meister on remote host '%s'"
                        " (pid %d), exit status: %d [%0X]",
                        host,
                        pid,
                        exit_status,
                        _exit_status,
                    )

    if failures > 0:
        logger.info("terminating tool meister startup due to failures")
        terminate_msg = dict(action="terminate", group=group, directory=None)
        try:
            ret = redis_server.publish(
                channel, json.dumps(terminate_msg, sort_keys=True)
            )
        except Exception:
            logger.exception("Failed to publish terminate message")
        else:
            logger.debug("publish() = %r", ret)
        ret_val = kill_redis_server(redis_pid)
    elif successes > 0:
        # If any successes, then we need to wait for them to show up as
        # subscribers.
        logger.debug(
            "waiting for all successfully spawned SSH processes"
            " to show up as subscribers"
        )
        pids = wait_for_subs(chan, successes, logger)
        # Record our collected pids.
        try:
            redis_server.set("tm-pids", json.dumps(pids, sort_keys=True))
        except Exception:
            logger.exception("failed to set tool meister pids object")
            ret_val = kill_redis_server(redis_pid)
        else:
            ret_val = 0
    else:
        logger.warning(
            "unable to successfully start any tool meisters,"
            " but encountered no failures either: terminating"
        )
        ret_val = kill_redis_server(redis_pid)
    return ret_val


if __name__ == "__main__":
    status = main(sys.argv)
    sys.exit(status)
