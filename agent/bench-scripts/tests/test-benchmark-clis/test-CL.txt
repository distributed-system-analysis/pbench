+++ Running test-CL test-benchmark-clis

Bench Script: pbench-cyclictest --help
------------
[warn][1900-01-01T00:00:00.000000] pbench-cyclictest is deprecated and will be removed in the next release
	The following options are available:

		-c str --config=str name of the test config
		-r --runtime[s] int[s|m|h][,int[s|m|h] one or more test measurement periods. s=seconds, m=minutes, h=hours (default is 1m)
		-C --cpu int                                  cpu to bind to
		-s --stress                                   run stress process on the same cpu as --cpu
		--tool-group=str
		--sysinfo=str,                                str= comma separated values of sysinfo to be collected
		                                                   available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-cyclictest --tool-group=bad --sysinfo=bad
------------
[warn][1900-01-01T00:00:00.000000] pbench-cyclictest is deprecated and will be removed in the next release
WARNING: pbench-cyclictest is deprecated and will be removed in the next release
	pbench-cyclictest: invalid --tool-group option ("bad"), directory not found: /var/tmp/pbench-test-bench/pbench-agent/tools-v1-bad
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
	pbench-cyclictest: invalid --sysinfo option ("bad")

	The following options are available:

		-c str --config=str name of the test config
		-r --runtime[s] int[s|m|h][,int[s|m|h] one or more test measurement periods. s=seconds, m=minutes, h=hours (default is 1m)
		-C --cpu int                                  cpu to bind to
		-s --stress                                   run stress process on the same cpu as --cpu
		--tool-group=str
		--sysinfo=str,                                str= comma separated values of sysinfo to be collected
		                                                   available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-cyclictest --bad-to-the-bone
------------
[warn][1900-01-01T00:00:00.000000] pbench-cyclictest is deprecated and will be removed in the next release
pbench-cyclictest --bad-to-the-bone

	unrecognized option specified

	The following options are available:

		-c str --config=str name of the test config
		-r --runtime[s] int[s|m|h][,int[s|m|h] one or more test measurement periods. s=seconds, m=minutes, h=hours (default is 1m)
		-C --cpu int                                  cpu to bind to
		-s --stress                                   run stress process on the same cpu as --cpu
		--tool-group=str
		--sysinfo=str,                                str= comma separated values of sysinfo to be collected
		                                                   available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-dbench --help
------------
[warn][1900-01-01T00:00:00.000000] pbench-dbench is deprecated and will be removed in the next release
	The following options are available:

		             --tool-group=str
		-c str       --config=str               name of the test config (i.e. jumbo_frames_and_network_throughput)
		-r int       --runtime=int              test measurement period in seconds (default is 60)
		-t int[,int] --threads=int[,int]        a list of the number of dbench threads to run (default is )
		-C str[,str] --client[s]=str[,str]      a list of one or more hostnames/IPs.  These systems will run the
		                                        dbench client (drive the test).
		                                        If this is omitted, the local system is the client
		             --client-node[s]=str[,str] An ordered list of client NUMA nodes which should be used for CPU binding
		                                        The order must correspond with the --clients list
		                                        To omit a specific client from binding, use a value of -1
		             --samples=int              the number of times each different test is run (to compute average &
		                                        standard deviations)
		             --max-failures=int         the maximm number of failures to get below stddev
		             --max-stddev=int           the maximm percent stddev allowed to pass
		             --postprocess-only=y|n     don't run the benchmark, but postprocess data from previous test
		             --run-dir=str              optionally specify what directory should be used (usually only used
		                                        if postprocess-only=y)
		             --start-iteration-num=int  optionally skip the first (n-1) tests
		             --tool-label-pattern=str   dbench will provide CPU and efficiency information for any tool directory
		                                        with a "^<pattern>" in the name, provided "sar" is one of the
		                                        registered tools.
		                                        a default pattern, "dbench-" is used if none is provided.
		                                        simply register your tools with "--label=dbench-$X", and this script
		                                        will genrate CPU_dbench-$X and MBps/CPU_dbench-$X
		                                        for all tools which have that pattern as a
		                                        prefix.  if you don't want to register your tools with "dbench-" as
		                                        part of the label, just use --tool-label-pattern= to tell this script
		                                        the prefix pattern to use for CPU information.
		             --sysinfo=str,             str= comma separated values of sysinfo to be collected
		                                             available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-dbench --tool-group=bad --sysinfo=bad
------------
[warn][1900-01-01T00:00:00.000000] pbench-dbench is deprecated and will be removed in the next release
WARNING: pbench-dbench is deprecated and will be removed in the next release
	pbench-dbench: invalid --tool-group option ("bad"), directory not found: /var/tmp/pbench-test-bench/pbench-agent/tools-v1-bad
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
	pbench-dbench: invalid --sysinfo option ("bad")

	The following options are available:

		             --tool-group=str
		-c str       --config=str               name of the test config (i.e. jumbo_frames_and_network_throughput)
		-r int       --runtime=int              test measurement period in seconds (default is 60)
		-t int[,int] --threads=int[,int]        a list of the number of dbench threads to run (default is )
		-C str[,str] --client[s]=str[,str]      a list of one or more hostnames/IPs.  These systems will run the
		                                        dbench client (drive the test).
		                                        If this is omitted, the local system is the client
		             --client-node[s]=str[,str] An ordered list of client NUMA nodes which should be used for CPU binding
		                                        The order must correspond with the --clients list
		                                        To omit a specific client from binding, use a value of -1
		             --samples=int              the number of times each different test is run (to compute average &
		                                        standard deviations)
		             --max-failures=int         the maximm number of failures to get below stddev
		             --max-stddev=int           the maximm percent stddev allowed to pass
		             --postprocess-only=y|n     don't run the benchmark, but postprocess data from previous test
		             --run-dir=str              optionally specify what directory should be used (usually only used
		                                        if postprocess-only=y)
		             --start-iteration-num=int  optionally skip the first (n-1) tests
		             --tool-label-pattern=str   dbench will provide CPU and efficiency information for any tool directory
		                                        with a "^<pattern>" in the name, provided "sar" is one of the
		                                        registered tools.
		                                        a default pattern, "dbench-" is used if none is provided.
		                                        simply register your tools with "--label=dbench-$X", and this script
		                                        will genrate CPU_dbench-$X and MBps/CPU_dbench-$X
		                                        for all tools which have that pattern as a
		                                        prefix.  if you don't want to register your tools with "dbench-" as
		                                        part of the label, just use --tool-label-pattern= to tell this script
		                                        the prefix pattern to use for CPU information.
		             --sysinfo=str,             str= comma separated values of sysinfo to be collected
		                                             available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-dbench --bad-to-the-bone
------------
[warn][1900-01-01T00:00:00.000000] pbench-dbench is deprecated and will be removed in the next release
pbench-dbench --bad-to-the-bone

	unrecognized option specified

	The following options are available:

		             --tool-group=str
		-c str       --config=str               name of the test config (i.e. jumbo_frames_and_network_throughput)
		-r int       --runtime=int              test measurement period in seconds (default is 60)
		-t int[,int] --threads=int[,int]        a list of the number of dbench threads to run (default is )
		-C str[,str] --client[s]=str[,str]      a list of one or more hostnames/IPs.  These systems will run the
		                                        dbench client (drive the test).
		                                        If this is omitted, the local system is the client
		             --client-node[s]=str[,str] An ordered list of client NUMA nodes which should be used for CPU binding
		                                        The order must correspond with the --clients list
		                                        To omit a specific client from binding, use a value of -1
		             --samples=int              the number of times each different test is run (to compute average &
		                                        standard deviations)
		             --max-failures=int         the maximm number of failures to get below stddev
		             --max-stddev=int           the maximm percent stddev allowed to pass
		             --postprocess-only=y|n     don't run the benchmark, but postprocess data from previous test
		             --run-dir=str              optionally specify what directory should be used (usually only used
		                                        if postprocess-only=y)
		             --start-iteration-num=int  optionally skip the first (n-1) tests
		             --tool-label-pattern=str   dbench will provide CPU and efficiency information for any tool directory
		                                        with a "^<pattern>" in the name, provided "sar" is one of the
		                                        registered tools.
		                                        a default pattern, "dbench-" is used if none is provided.
		                                        simply register your tools with "--label=dbench-$X", and this script
		                                        will genrate CPU_dbench-$X and MBps/CPU_dbench-$X
		                                        for all tools which have that pattern as a
		                                        prefix.  if you don't want to register your tools with "dbench-" as
		                                        part of the label, just use --tool-label-pattern= to tell this script
		                                        the prefix pattern to use for CPU information.
		             --sysinfo=str,             str= comma separated values of sysinfo to be collected
		                                             available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-fio --help
------------
The following options are available:

	-t str[,str...] --test-types=str[,str...]
		one or more of read,write,rw,randread,randwrite,randrw

	--direct=[0/1]
		1 = O_DIRECT enabled (default), 0 = O_DIRECT disabled

	--sync=[0/1]
		1 = O_SYNC enabled, 0 = O_SYNC disabled (default)

	--rate-iops=int
		do not exceeed this IOP rate (per job, per client)

	-r int --runtime=int
		runtime in seconds (default is )

	--ramptime=int
		time in seconds to warm up test before taking measurements (default is )

	-b int[,int...] --block-sizes=int[,int...] (default is 4,64,1024)
		one or more block sizes in KiB

	-s int[,int...] --file-size=int[,int...] (no default)
		file sizes in MiB

	-d str[,str...] --targets=str[,str...]
		one or more files, block devices, or directories (default is /tmp/fio);
		use of persistent names for block devices is highly recommended;
		when a directory is specified, one must also provide a job file
		via '--job-file=<path>' which employs the 'directory = $target'
		syntax, or use the predefined job file provided at:
		  /var/tmp/pbench-test-bench/opt/pbench-agent/bench-scripts/templates/fio-shared-fs.job

	-j str --job-mode=str    str=[serial|concurrent]  (default is 'concurrent')
		directs how --targets parameter(s) is/are used; with 'serial' mode all combinations
		of fio job parameters are run against each target one at a time, while with 'concurrent'
		mode all target devices are used at the same time.

	--ioengine=str           str= any ioengine fio supports (default is )

	--iodepth=<int>		Set the iodepth config variable in the fio job file

	-c str[,str...] --clients=str[,str...]      str= a list of one or more host names (hosta,hostb,hostc) where you want fio to run
		If no clients are specified, fio is run locally
		Note: the pbench-agent must be installed on each of the client systems already.

	--client-file=str        str= file (with absolute path) which contains 1 client per line

	--config=str
		name of the test configuration

	--tool-group=str

	--postprocess-only=[y|n]
		use this only if you want to postprocess an existing result again
		you must use --run-dir option with this

	--run-dir=<path>
		provide the path of an existig result (typically somewhere in /var/tmp/pbench-test-bench/pbench-agent

	--numjobs=<int>
		number of jobs to run, if not given then fio default of numjobs=1 will be used

	--job-file=<path>
		provide the path of a fio job config file, (default is /var/tmp/pbench-test-bench/opt/pbench-agent/bench-scripts/templates/fio.job)

	--pre-iteration-script=str
		use executable script/program to prepare the system for test iteration
		example: --pre-iteration-script=$HOME/drop-cache.sh

	--samples=<int>
		number of samples to use per test iteration (default is 5)

	--max-stddev=<int>
		the maximum percent stddev allowed to pass

	--max-failures=<int>
		the maximum number of failures to get below stddev

	--histogram-interval-sec=<int>
		set the histogram logging interval in seconds (default 10)

	--sysinfo=str            str= comma separated values of sysinfo to be collected
		available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

	--unique-ports           Use unique ports for each server

Bench Script: pbench-fio --tool-group=bad --sysinfo=bad
------------
	pbench-fio: invalid --tool-group option ("bad"), directory not found: /var/tmp/pbench-test-bench/pbench-agent/tools-v1-bad
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
	pbench-fio: invalid --sysinfo option ("bad")

The following options are available:

	-t str[,str...] --test-types=str[,str...]
		one or more of read,write,rw,randread,randwrite,randrw

	--direct=[0/1]
		1 = O_DIRECT enabled (default), 0 = O_DIRECT disabled

	--sync=[0/1]
		1 = O_SYNC enabled, 0 = O_SYNC disabled (default)

	--rate-iops=int
		do not exceeed this IOP rate (per job, per client)

	-r int --runtime=int
		runtime in seconds (default is )

	--ramptime=int
		time in seconds to warm up test before taking measurements (default is )

	-b int[,int...] --block-sizes=int[,int...] (default is 4,64,1024)
		one or more block sizes in KiB

	-s int[,int...] --file-size=int[,int...] (no default)
		file sizes in MiB

	-d str[,str...] --targets=str[,str...]
		one or more files, block devices, or directories (default is /tmp/fio);
		use of persistent names for block devices is highly recommended;
		when a directory is specified, one must also provide a job file
		via '--job-file=<path>' which employs the 'directory = $target'
		syntax, or use the predefined job file provided at:
		  /var/tmp/pbench-test-bench/opt/pbench-agent/bench-scripts/templates/fio-shared-fs.job

	-j str --job-mode=str    str=[serial|concurrent]  (default is 'concurrent')
		directs how --targets parameter(s) is/are used; with 'serial' mode all combinations
		of fio job parameters are run against each target one at a time, while with 'concurrent'
		mode all target devices are used at the same time.

	--ioengine=str           str= any ioengine fio supports (default is )

	--iodepth=<int>		Set the iodepth config variable in the fio job file

	-c str[,str...] --clients=str[,str...]      str= a list of one or more host names (hosta,hostb,hostc) where you want fio to run
		If no clients are specified, fio is run locally
		Note: the pbench-agent must be installed on each of the client systems already.

	--client-file=str        str= file (with absolute path) which contains 1 client per line

	--config=str
		name of the test configuration

	--tool-group=str

	--postprocess-only=[y|n]
		use this only if you want to postprocess an existing result again
		you must use --run-dir option with this

	--run-dir=<path>
		provide the path of an existig result (typically somewhere in /var/tmp/pbench-test-bench/pbench-agent

	--numjobs=<int>
		number of jobs to run, if not given then fio default of numjobs=1 will be used

	--job-file=<path>
		provide the path of a fio job config file, (default is /var/tmp/pbench-test-bench/opt/pbench-agent/bench-scripts/templates/fio.job)

	--pre-iteration-script=str
		use executable script/program to prepare the system for test iteration
		example: --pre-iteration-script=$HOME/drop-cache.sh

	--samples=<int>
		number of samples to use per test iteration (default is 5)

	--max-stddev=<int>
		the maximum percent stddev allowed to pass

	--max-failures=<int>
		the maximum number of failures to get below stddev

	--histogram-interval-sec=<int>
		set the histogram logging interval in seconds (default 10)

	--sysinfo=str            str= comma separated values of sysinfo to be collected
		available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

	--unique-ports           Use unique ports for each server

Bench Script: pbench-fio --bad-to-the-bone
------------
pbench-fio --bad-to-the-bone

	unrecognized option specified

The following options are available:

	-t str[,str...] --test-types=str[,str...]
		one or more of read,write,rw,randread,randwrite,randrw

	--direct=[0/1]
		1 = O_DIRECT enabled (default), 0 = O_DIRECT disabled

	--sync=[0/1]
		1 = O_SYNC enabled, 0 = O_SYNC disabled (default)

	--rate-iops=int
		do not exceeed this IOP rate (per job, per client)

	-r int --runtime=int
		runtime in seconds (default is )

	--ramptime=int
		time in seconds to warm up test before taking measurements (default is )

	-b int[,int...] --block-sizes=int[,int...] (default is 4,64,1024)
		one or more block sizes in KiB

	-s int[,int...] --file-size=int[,int...] (no default)
		file sizes in MiB

	-d str[,str...] --targets=str[,str...]
		one or more files, block devices, or directories (default is /tmp/fio);
		use of persistent names for block devices is highly recommended;
		when a directory is specified, one must also provide a job file
		via '--job-file=<path>' which employs the 'directory = $target'
		syntax, or use the predefined job file provided at:
		  /var/tmp/pbench-test-bench/opt/pbench-agent/bench-scripts/templates/fio-shared-fs.job

	-j str --job-mode=str    str=[serial|concurrent]  (default is 'concurrent')
		directs how --targets parameter(s) is/are used; with 'serial' mode all combinations
		of fio job parameters are run against each target one at a time, while with 'concurrent'
		mode all target devices are used at the same time.

	--ioengine=str           str= any ioengine fio supports (default is )

	--iodepth=<int>		Set the iodepth config variable in the fio job file

	-c str[,str...] --clients=str[,str...]      str= a list of one or more host names (hosta,hostb,hostc) where you want fio to run
		If no clients are specified, fio is run locally
		Note: the pbench-agent must be installed on each of the client systems already.

	--client-file=str        str= file (with absolute path) which contains 1 client per line

	--config=str
		name of the test configuration

	--tool-group=str

	--postprocess-only=[y|n]
		use this only if you want to postprocess an existing result again
		you must use --run-dir option with this

	--run-dir=<path>
		provide the path of an existig result (typically somewhere in /var/tmp/pbench-test-bench/pbench-agent

	--numjobs=<int>
		number of jobs to run, if not given then fio default of numjobs=1 will be used

	--job-file=<path>
		provide the path of a fio job config file, (default is /var/tmp/pbench-test-bench/opt/pbench-agent/bench-scripts/templates/fio.job)

	--pre-iteration-script=str
		use executable script/program to prepare the system for test iteration
		example: --pre-iteration-script=$HOME/drop-cache.sh

	--samples=<int>
		number of samples to use per test iteration (default is 5)

	--max-stddev=<int>
		the maximum percent stddev allowed to pass

	--max-failures=<int>
		the maximum number of failures to get below stddev

	--histogram-interval-sec=<int>
		set the histogram logging interval in seconds (default 10)

	--sysinfo=str            str= comma separated values of sysinfo to be collected
		available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

	--unique-ports           Use unique ports for each server

Bench Script: pbench-iozone --help
------------
[warn][1900-01-01T00:00:00.000000] pbench-iozone is deprecated and will be removed in the next release
	The following options are available:

		-C str --config=str name of the test config
		-d str[,str] --targets=str[,str]
			file to use for iozone test in format /dir/file - this is iozone : -f option
		-s str[,str] --file_sizes=str[,str]
			one or more file_sizes sizes to use
		-r str[,str] --record_sizes=str[,str]
			one or more record_sizes sizes to use
		-n str[,str] --number_of_runs=str[,str]
			number of iozone runs - default is 10 runs
		--tool-group=str
		--sysinfo=str, str= comma separated values of sysinfo to be collected
		                    available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-iozone --tool-group=bad --sysinfo=bad
------------
[warn][1900-01-01T00:00:00.000000] pbench-iozone is deprecated and will be removed in the next release
WARNING: pbench-iozone is deprecated and will be removed in the next release
	pbench-iozone: invalid --tool-group option ("bad"), directory not found: /var/tmp/pbench-test-bench/pbench-agent/tools-v1-bad
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
	pbench-iozone: invalid --sysinfo option ("bad")

	The following options are available:

		-C str --config=str name of the test config
		-d str[,str] --targets=str[,str]
			file to use for iozone test in format /dir/file - this is iozone : -f option
		-s str[,str] --file_sizes=str[,str]
			one or more file_sizes sizes to use
		-r str[,str] --record_sizes=str[,str]
			one or more record_sizes sizes to use
		-n str[,str] --number_of_runs=str[,str]
			number of iozone runs - default is 10 runs
		--tool-group=str
		--sysinfo=str, str= comma separated values of sysinfo to be collected
		                    available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-iozone --bad-to-the-bone
------------
[warn][1900-01-01T00:00:00.000000] pbench-iozone is deprecated and will be removed in the next release
pbench-iozone --bad-to-the-bone

	unrecognized option specified

	The following options are available:

		-C str --config=str name of the test config
		-d str[,str] --targets=str[,str]
			file to use for iozone test in format /dir/file - this is iozone : -f option
		-s str[,str] --file_sizes=str[,str]
			one or more file_sizes sizes to use
		-r str[,str] --record_sizes=str[,str]
			one or more record_sizes sizes to use
		-n str[,str] --number_of_runs=str[,str]
			number of iozone runs - default is 10 runs
		--tool-group=str
		--sysinfo=str, str= comma separated values of sysinfo to be collected
		                    available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-linpack --help
------------
The following options are available:

	-C str --config=str         name of the test config
	-c str[,str...] --clients=str[,str...]      a list of one or more host names (hosta,hostb,hostc) where you want pbench-linpack to run
	       --samples=<int>      number of samples to use per test iteration (default is 2)
	       --threads=int[,int]  number of threads to use (default is # local CPUs)
	       --tool-group=str
	       --sysinfo=str,       str= comma separated values of sysinfo to be collected
	                                available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-linpack --tool-group=bad --sysinfo=bad
------------
	pbench-linpack: invalid --tool-group option ("bad"), directory not found: /var/tmp/pbench-test-bench/pbench-agent/tools-v1-bad
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
	pbench-linpack: invalid --sysinfo option ("bad")

The following options are available:

	-C str --config=str         name of the test config
	-c str[,str...] --clients=str[,str...]      a list of one or more host names (hosta,hostb,hostc) where you want pbench-linpack to run
	       --samples=<int>      number of samples to use per test iteration (default is 2)
	       --threads=int[,int]  number of threads to use (default is # local CPUs)
	       --tool-group=str
	       --sysinfo=str,       str= comma separated values of sysinfo to be collected
	                                available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-linpack --bad-to-the-bone
------------
pbench-linpack --bad-to-the-bone

	unrecognized option specified

The following options are available:

	-C str --config=str         name of the test config
	-c str[,str...] --clients=str[,str...]      a list of one or more host names (hosta,hostb,hostc) where you want pbench-linpack to run
	       --samples=<int>      number of samples to use per test iteration (default is 2)
	       --threads=int[,int]  number of threads to use (default is # local CPUs)
	       --tool-group=str
	       --sysinfo=str,       str= comma separated values of sysinfo to be collected
	                                available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-migrate --help
------------
[warn][1900-01-01T00:00:00.000000] pbench-migrate is deprecated and will be removed in the next release
	The following options are available:

		--tool-group=str
		--vm=str                                name of vm to migrate
		--src-host=str                          host to migrate from
		--dest-host=str                         host to migrate to
		--src-ipaddr=str                        optional IP address to migrate from
		--dest-ipaddr=str                       optional IP address to migrate to
		--timeout=int                           optional timeout in seconds
		--postprocess=str                       skip = don't postprocess, only = only postprocess existing test, yes (default) = postprocess after test
		--seconds-before-migrate=int            wait this many seconds before starting the migration
		--seconds-before-postprocess=int        wait this many seconds before postprocessing the data
		--max-downtime                          maximum downtime in milliseconds
		--compache-size                         maximum size in bytes of cache used for compression
		--speed                                 maximum network speed in MiB/sec
		--round-trips=int                       the number of times to live-migrate back & forth (default is 0)
		--use-libvirt=y/n                       iif this is n, then migration is done with qemu directly
		                                        0 = 1 migration, just to dest-host (no round-trip migration, VM ends up on dest-host).
		                                        1 = 2 migrations, 2 = 4 migrations, etc.  VM ends up on src-host
		--sysinfo=str,                          str= comma separated values of sysinfo to be collected
		                                             available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-migrate --tool-group=bad --sysinfo=bad
------------
[warn][1900-01-01T00:00:00.000000] pbench-migrate is deprecated and will be removed in the next release
WARNING: pbench-migrate is deprecated and will be removed in the next release
	pbench-migrate: invalid --tool-group option ("bad"), directory not found: /var/tmp/pbench-test-bench/pbench-agent/tools-v1-bad
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
	pbench-migrate: invalid --sysinfo option ("bad")

	The following options are available:

		--tool-group=str
		--vm=str                                name of vm to migrate
		--src-host=str                          host to migrate from
		--dest-host=str                         host to migrate to
		--src-ipaddr=str                        optional IP address to migrate from
		--dest-ipaddr=str                       optional IP address to migrate to
		--timeout=int                           optional timeout in seconds
		--postprocess=str                       skip = don't postprocess, only = only postprocess existing test, yes (default) = postprocess after test
		--seconds-before-migrate=int            wait this many seconds before starting the migration
		--seconds-before-postprocess=int        wait this many seconds before postprocessing the data
		--max-downtime                          maximum downtime in milliseconds
		--compache-size                         maximum size in bytes of cache used for compression
		--speed                                 maximum network speed in MiB/sec
		--round-trips=int                       the number of times to live-migrate back & forth (default is 0)
		--use-libvirt=y/n                       iif this is n, then migration is done with qemu directly
		                                        0 = 1 migration, just to dest-host (no round-trip migration, VM ends up on dest-host).
		                                        1 = 2 migrations, 2 = 4 migrations, etc.  VM ends up on src-host
		--sysinfo=str,                          str= comma separated values of sysinfo to be collected
		                                             available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-migrate --bad-to-the-bone
------------
[warn][1900-01-01T00:00:00.000000] pbench-migrate is deprecated and will be removed in the next release
pbench-migrate --bad-to-the-bone

	unrecognized option specified

	The following options are available:

		--tool-group=str
		--vm=str                                name of vm to migrate
		--src-host=str                          host to migrate from
		--dest-host=str                         host to migrate to
		--src-ipaddr=str                        optional IP address to migrate from
		--dest-ipaddr=str                       optional IP address to migrate to
		--timeout=int                           optional timeout in seconds
		--postprocess=str                       skip = don't postprocess, only = only postprocess existing test, yes (default) = postprocess after test
		--seconds-before-migrate=int            wait this many seconds before starting the migration
		--seconds-before-postprocess=int        wait this many seconds before postprocessing the data
		--max-downtime                          maximum downtime in milliseconds
		--compache-size                         maximum size in bytes of cache used for compression
		--speed                                 maximum network speed in MiB/sec
		--round-trips=int                       the number of times to live-migrate back & forth (default is 0)
		--use-libvirt=y/n                       iif this is n, then migration is done with qemu directly
		                                        0 = 1 migration, just to dest-host (no round-trip migration, VM ends up on dest-host).
		                                        1 = 2 migrations, 2 = 4 migrations, etc.  VM ends up on src-host
		--sysinfo=str,                          str= comma separated values of sysinfo to be collected
		                                             available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-netperf --help
------------
[warn][1900-01-01T00:00:00.000000] pbench-netperf is deprecated and will be removed in the next release
	The following options are available:

		             --tool-group=str
		-c str       --config=str                   name of the test config (i.e. jumbo_frames_and_network_throughput)
		-t str[,str] --test-types=str[,str]         can be stream, maerts, bidirect, and/or rr (default stream,maerts,bidirec,rr)
		-r int       --runtime=int                  test measurement period in seconds (default is 60)
		-m int[,int] --message-sizes=str[,str]      list of message sizes in bytes (default is 1,64,1024,16384)
		-p str[,str] --protocols=str[,str]          tcp and/or udp (default is tcp,udp)
		-i int[,int] --instances=int[,int]          list of number of netperf instances to run (default is 1,8,64)
		-C str[,str] --client[s]=str[,str]          a list of one or more hostnames/IPs.  These systems will run the
		                                            netperf client (drive the test).
		                                            If this is omitted, the local system is the client
		                                            Note: the number of clients and server must be the same!
		                                            Clients and servers are paired according the order in the list (first
		                                            client pairs with firest server, etc)
		-S str[,str] --server[s]=str[,str]          a list of one or more hostnames/IPs.  These systems will run the netperf
		                                            server (listening for connections)
		                                            If this is omitted, the server will listen on the local system
		                                            loopback interface
		             --samples=int                  the number of times each different test is run (to compute average &
		                                            standard deviations)
		             --max-failures=int             the maximm number of failures to get below stddev
		             --max-stddev=int               the maximm percent stddev allowed to pass
		             --postprocess-only=y|n         don't run the benchmark, but postprocess data from previous test
		             --run-dir=str                  optionally specify what directory should be used (usually only used
		                                            if postprocess-only=y)
		             --start-iteration-num=int      optionally skip the first (n-1) tests
		             --log-response-times=y|n       record the response time of every single operation
		             --client-label=str             provide the pbench netperf-client tool label and postprocessing will
		                                            compute a netperf-client result/CPU metric
		             --server-label=str             provide the pbench netperf-server tool label and postprocessing will
		                                            compute a netperf-server result/CPU metric
		             --sysinfo=str,                 str= comma separated values of sysinfo to be collected
		                                                 available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-netperf --tool-group=bad --sysinfo=bad
------------
[warn][1900-01-01T00:00:00.000000] pbench-netperf is deprecated and will be removed in the next release
WARNING: pbench-netperf is deprecated and will be removed in the next release
	pbench-netperf: invalid --tool-group option ("bad"), directory not found: /var/tmp/pbench-test-bench/pbench-agent/tools-v1-bad
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
	pbench-netperf: invalid --sysinfo option ("bad")

	The following options are available:

		             --tool-group=str
		-c str       --config=str                   name of the test config (i.e. jumbo_frames_and_network_throughput)
		-t str[,str] --test-types=str[,str]         can be stream, maerts, bidirect, and/or rr (default stream,maerts,bidirec,rr)
		-r int       --runtime=int                  test measurement period in seconds (default is 60)
		-m int[,int] --message-sizes=str[,str]      list of message sizes in bytes (default is 1,64,1024,16384)
		-p str[,str] --protocols=str[,str]          tcp and/or udp (default is tcp,udp)
		-i int[,int] --instances=int[,int]          list of number of netperf instances to run (default is 1,8,64)
		-C str[,str] --client[s]=str[,str]          a list of one or more hostnames/IPs.  These systems will run the
		                                            netperf client (drive the test).
		                                            If this is omitted, the local system is the client
		                                            Note: the number of clients and server must be the same!
		                                            Clients and servers are paired according the order in the list (first
		                                            client pairs with firest server, etc)
		-S str[,str] --server[s]=str[,str]          a list of one or more hostnames/IPs.  These systems will run the netperf
		                                            server (listening for connections)
		                                            If this is omitted, the server will listen on the local system
		                                            loopback interface
		             --samples=int                  the number of times each different test is run (to compute average &
		                                            standard deviations)
		             --max-failures=int             the maximm number of failures to get below stddev
		             --max-stddev=int               the maximm percent stddev allowed to pass
		             --postprocess-only=y|n         don't run the benchmark, but postprocess data from previous test
		             --run-dir=str                  optionally specify what directory should be used (usually only used
		                                            if postprocess-only=y)
		             --start-iteration-num=int      optionally skip the first (n-1) tests
		             --log-response-times=y|n       record the response time of every single operation
		             --client-label=str             provide the pbench netperf-client tool label and postprocessing will
		                                            compute a netperf-client result/CPU metric
		             --server-label=str             provide the pbench netperf-server tool label and postprocessing will
		                                            compute a netperf-server result/CPU metric
		             --sysinfo=str,                 str= comma separated values of sysinfo to be collected
		                                                 available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-netperf --bad-to-the-bone
------------
[warn][1900-01-01T00:00:00.000000] pbench-netperf is deprecated and will be removed in the next release
pbench-netperf --bad-to-the-bone

	unrecognized option specified

	The following options are available:

		             --tool-group=str
		-c str       --config=str                   name of the test config (i.e. jumbo_frames_and_network_throughput)
		-t str[,str] --test-types=str[,str]         can be stream, maerts, bidirect, and/or rr (default stream,maerts,bidirec,rr)
		-r int       --runtime=int                  test measurement period in seconds (default is 60)
		-m int[,int] --message-sizes=str[,str]      list of message sizes in bytes (default is 1,64,1024,16384)
		-p str[,str] --protocols=str[,str]          tcp and/or udp (default is tcp,udp)
		-i int[,int] --instances=int[,int]          list of number of netperf instances to run (default is 1,8,64)
		-C str[,str] --client[s]=str[,str]          a list of one or more hostnames/IPs.  These systems will run the
		                                            netperf client (drive the test).
		                                            If this is omitted, the local system is the client
		                                            Note: the number of clients and server must be the same!
		                                            Clients and servers are paired according the order in the list (first
		                                            client pairs with firest server, etc)
		-S str[,str] --server[s]=str[,str]          a list of one or more hostnames/IPs.  These systems will run the netperf
		                                            server (listening for connections)
		                                            If this is omitted, the server will listen on the local system
		                                            loopback interface
		             --samples=int                  the number of times each different test is run (to compute average &
		                                            standard deviations)
		             --max-failures=int             the maximm number of failures to get below stddev
		             --max-stddev=int               the maximm percent stddev allowed to pass
		             --postprocess-only=y|n         don't run the benchmark, but postprocess data from previous test
		             --run-dir=str                  optionally specify what directory should be used (usually only used
		                                            if postprocess-only=y)
		             --start-iteration-num=int      optionally skip the first (n-1) tests
		             --log-response-times=y|n       record the response time of every single operation
		             --client-label=str             provide the pbench netperf-client tool label and postprocessing will
		                                            compute a netperf-client result/CPU metric
		             --server-label=str             provide the pbench netperf-server tool label and postprocessing will
		                                            compute a netperf-server result/CPU metric
		             --sysinfo=str,                 str= comma separated values of sysinfo to be collected
		                                                 available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-specjbb2005 --help
------------
	The following options are available:

		-C str --config=<str>            name of the test config
		-j str --java-opts=<str>         options passed directly to the JVM
		       --nr-jvms=<int>|node      number of JVMs. if = node, number of JVMs = number of NUMA nodes
		       --start-warehouses=<int>  number of warehouses to start with (default is 1)
		       --inc-warehouses=<int>    number of warehouses to increment by (default is 1)
		       --stop-warehouses=<int>   number of warehouses to stop with (default is nr_cpus * 2 / nr_jvms)
		       --heap-size=<str>         size of the heap, java size spec (default is 4096m)
		       --runtime=<int>           measurement period in seconds (default is 30)
		-d str --dir=<str>               directory to run the test
		       --tool-group=<str>        tool group to use during test
		       --sysinfo=<str,>          comma separated values of sysinfo to be collected
		                                      available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology
		       --specjbb2005-dir=<str>   the location of the install directory for SPECjbb2005
		                                      (default is /usr/local/share/specjbb2005)

Bench Script: pbench-specjbb2005 --tool-group=bad --sysinfo=bad
------------
	pbench-specjbb2005: invalid --tool-group option ("bad"), directory not found: /var/tmp/pbench-test-bench/pbench-agent/tools-v1-bad
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
	pbench-specjbb2005: invalid --sysinfo option ("bad")

	The following options are available:

		-C str --config=<str>            name of the test config
		-j str --java-opts=<str>         options passed directly to the JVM
		       --nr-jvms=<int>|node      number of JVMs. if = node, number of JVMs = number of NUMA nodes
		       --start-warehouses=<int>  number of warehouses to start with (default is 1)
		       --inc-warehouses=<int>    number of warehouses to increment by (default is 1)
		       --stop-warehouses=<int>   number of warehouses to stop with (default is nr_cpus * 2 / nr_jvms)
		       --heap-size=<str>         size of the heap, java size spec (default is 4096m)
		       --runtime=<int>           measurement period in seconds (default is 30)
		-d str --dir=<str>               directory to run the test
		       --tool-group=<str>        tool group to use during test
		       --sysinfo=<str,>          comma separated values of sysinfo to be collected
		                                      available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology
		       --specjbb2005-dir=<str>   the location of the install directory for SPECjbb2005
		                                      (default is /usr/local/share/specjbb2005)

Bench Script: pbench-specjbb2005 --bad-to-the-bone
------------
pbench-specjbb2005 --bad-to-the-bone

	unrecognized option specified

	The following options are available:

		-C str --config=<str>            name of the test config
		-j str --java-opts=<str>         options passed directly to the JVM
		       --nr-jvms=<int>|node      number of JVMs. if = node, number of JVMs = number of NUMA nodes
		       --start-warehouses=<int>  number of warehouses to start with (default is 1)
		       --inc-warehouses=<int>    number of warehouses to increment by (default is 1)
		       --stop-warehouses=<int>   number of warehouses to stop with (default is nr_cpus * 2 / nr_jvms)
		       --heap-size=<str>         size of the heap, java size spec (default is 4096m)
		       --runtime=<int>           measurement period in seconds (default is 30)
		-d str --dir=<str>               directory to run the test
		       --tool-group=<str>        tool group to use during test
		       --sysinfo=<str,>          comma separated values of sysinfo to be collected
		                                      available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology
		       --specjbb2005-dir=<str>   the location of the install directory for SPECjbb2005
		                                      (default is /usr/local/share/specjbb2005)

Bench Script: pbench-uperf --help
------------
	The following options are available:

	--tool-group=str
	-c str       --config=str               name of the test config (e.g. jumbo_frames_and_network_throughput)
	-t str[,str] --test-types=str[,str]     can be stream, maerts, bidirec, and/or rr (default stream,maerts,bidirec,rr)
	-r int       --runtime=int              test measurement period in seconds (default is 60)
	-m int[,int] --message-sizes=str[,str]  list of message sizes in bytes (default is 1,64,1024,16384)
	-p str[,str] --protocols=str[,str]      tcp and/or udp (default is tcp,udp)
	-i int[,int] --instances=int[,int]      list of number of uperf instances to run (default is 1,8,64)
	-C str[,str] --client[s]=str[,str]      a list of one or more hostnames/IPs.  These systems will run the
				   uperf client (drive the test).
				   If this is omitted, the local system is the client.
				   Note: the number of clients and servers must be the same!
				   Clients and servers are paired according to the order in the list (first
				   client pairs with first server, etc)
	-S str[,str] --server[s]=str[,str]      a list of one or more hostnames/IPs.  These systems will run the uperf
				   server (listening for connections).
				   If this is omitted, the server will listen on the local system
				   loopback interface.
	--vsock-server[s]=str[,str]             a list of one or more AF_VSOCK hostnames, used instead of the server
				   hostnames, and directs uperf to use the AF_VSOCK protocol
				   The number of --vsock-servers provided must match the number of --servers
	--server-node[s]=str[,str]              An ordered list of server NUMA nodes which should be used for CPU binding
	--client-node[s]=str[,str]              An ordered list of client NUMA nodes which should be used for CPU binding
				   For both options above, the order must correspond with the --clients/--servers list
				   To omit a specific client/server from binding, use a value of -1.
	--samples=int              the number of times each different test is run (to compute average &
				   standard deviations).
	--max-failures=int         the maximum number of failures to get below stddev.
	--max-stddev=int           the maximum percent stddev allowed to pass.
	--postprocess-only=y|n     don't run the benchmark, but postprocess data from previous test.
	--run-dir=str              optionally specify what directory should be used (usually only used
				   if postprocess-only=y).
	--start-iteration-num=int  optionally skip the first (n-1) tests.
	--log-response-times=y|n   record the response time of every single operation.
	--tool-label-pattern=str   uperf will provide CPU and efficiency information for any tool directory
				   with a "^<pattern>" in the name, provided "sar" is one of the
				   registered tools.
				   a default pattern, "uperf-" is used if none is provided.
				   simply register your tools with "--label=uperf-$X", and this script
				   will generate CPU_uperf-$X and Gbps/CPU_uperf-$X or
				   trans_sec/CPU-uperf-$X for all tools which have that pattern as a
				   prefix.  If you don't want to register your tools with "uperf-" as
				   part of the label, just use --tool-label-pattern= to tell this script
				   the prefix pattern to use for CPU information.
	--sysinfo=str,             str= comma separated values of sysinfo to be collected
	                                available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-uperf --tool-group=bad --sysinfo=bad
------------
	pbench-uperf: invalid --tool-group option ("bad"), directory not found: /var/tmp/pbench-test-bench/pbench-agent/tools-v1-bad
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
	pbench-uperf: invalid --sysinfo option ("bad")

	The following options are available:

	--tool-group=str
	-c str       --config=str               name of the test config (e.g. jumbo_frames_and_network_throughput)
	-t str[,str] --test-types=str[,str]     can be stream, maerts, bidirec, and/or rr (default stream,maerts,bidirec,rr)
	-r int       --runtime=int              test measurement period in seconds (default is 60)
	-m int[,int] --message-sizes=str[,str]  list of message sizes in bytes (default is 1,64,1024,16384)
	-p str[,str] --protocols=str[,str]      tcp and/or udp (default is tcp,udp)
	-i int[,int] --instances=int[,int]      list of number of uperf instances to run (default is 1,8,64)
	-C str[,str] --client[s]=str[,str]      a list of one or more hostnames/IPs.  These systems will run the
				   uperf client (drive the test).
				   If this is omitted, the local system is the client.
				   Note: the number of clients and servers must be the same!
				   Clients and servers are paired according to the order in the list (first
				   client pairs with first server, etc)
	-S str[,str] --server[s]=str[,str]      a list of one or more hostnames/IPs.  These systems will run the uperf
				   server (listening for connections).
				   If this is omitted, the server will listen on the local system
				   loopback interface.
	--vsock-server[s]=str[,str]             a list of one or more AF_VSOCK hostnames, used instead of the server
				   hostnames, and directs uperf to use the AF_VSOCK protocol
				   The number of --vsock-servers provided must match the number of --servers
	--server-node[s]=str[,str]              An ordered list of server NUMA nodes which should be used for CPU binding
	--client-node[s]=str[,str]              An ordered list of client NUMA nodes which should be used for CPU binding
				   For both options above, the order must correspond with the --clients/--servers list
				   To omit a specific client/server from binding, use a value of -1.
	--samples=int              the number of times each different test is run (to compute average &
				   standard deviations).
	--max-failures=int         the maximum number of failures to get below stddev.
	--max-stddev=int           the maximum percent stddev allowed to pass.
	--postprocess-only=y|n     don't run the benchmark, but postprocess data from previous test.
	--run-dir=str              optionally specify what directory should be used (usually only used
				   if postprocess-only=y).
	--start-iteration-num=int  optionally skip the first (n-1) tests.
	--log-response-times=y|n   record the response time of every single operation.
	--tool-label-pattern=str   uperf will provide CPU and efficiency information for any tool directory
				   with a "^<pattern>" in the name, provided "sar" is one of the
				   registered tools.
				   a default pattern, "uperf-" is used if none is provided.
				   simply register your tools with "--label=uperf-$X", and this script
				   will generate CPU_uperf-$X and Gbps/CPU_uperf-$X or
				   trans_sec/CPU-uperf-$X for all tools which have that pattern as a
				   prefix.  If you don't want to register your tools with "uperf-" as
				   part of the label, just use --tool-label-pattern= to tell this script
				   the prefix pattern to use for CPU information.
	--sysinfo=str,             str= comma separated values of sysinfo to be collected
	                                available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-uperf --bad-to-the-bone
------------
pbench-uperf --bad-to-the-bone

	unrecognized option specified

	The following options are available:

	--tool-group=str
	-c str       --config=str               name of the test config (e.g. jumbo_frames_and_network_throughput)
	-t str[,str] --test-types=str[,str]     can be stream, maerts, bidirec, and/or rr (default stream,maerts,bidirec,rr)
	-r int       --runtime=int              test measurement period in seconds (default is 60)
	-m int[,int] --message-sizes=str[,str]  list of message sizes in bytes (default is 1,64,1024,16384)
	-p str[,str] --protocols=str[,str]      tcp and/or udp (default is tcp,udp)
	-i int[,int] --instances=int[,int]      list of number of uperf instances to run (default is 1,8,64)
	-C str[,str] --client[s]=str[,str]      a list of one or more hostnames/IPs.  These systems will run the
				   uperf client (drive the test).
				   If this is omitted, the local system is the client.
				   Note: the number of clients and servers must be the same!
				   Clients and servers are paired according to the order in the list (first
				   client pairs with first server, etc)
	-S str[,str] --server[s]=str[,str]      a list of one or more hostnames/IPs.  These systems will run the uperf
				   server (listening for connections).
				   If this is omitted, the server will listen on the local system
				   loopback interface.
	--vsock-server[s]=str[,str]             a list of one or more AF_VSOCK hostnames, used instead of the server
				   hostnames, and directs uperf to use the AF_VSOCK protocol
				   The number of --vsock-servers provided must match the number of --servers
	--server-node[s]=str[,str]              An ordered list of server NUMA nodes which should be used for CPU binding
	--client-node[s]=str[,str]              An ordered list of client NUMA nodes which should be used for CPU binding
				   For both options above, the order must correspond with the --clients/--servers list
				   To omit a specific client/server from binding, use a value of -1.
	--samples=int              the number of times each different test is run (to compute average &
				   standard deviations).
	--max-failures=int         the maximum number of failures to get below stddev.
	--max-stddev=int           the maximum percent stddev allowed to pass.
	--postprocess-only=y|n     don't run the benchmark, but postprocess data from previous test.
	--run-dir=str              optionally specify what directory should be used (usually only used
				   if postprocess-only=y).
	--start-iteration-num=int  optionally skip the first (n-1) tests.
	--log-response-times=y|n   record the response time of every single operation.
	--tool-label-pattern=str   uperf will provide CPU and efficiency information for any tool directory
				   with a "^<pattern>" in the name, provided "sar" is one of the
				   registered tools.
				   a default pattern, "uperf-" is used if none is provided.
				   simply register your tools with "--label=uperf-$X", and this script
				   will generate CPU_uperf-$X and Gbps/CPU_uperf-$X or
				   trans_sec/CPU-uperf-$X for all tools which have that pattern as a
				   prefix.  If you don't want to register your tools with "uperf-" as
				   part of the label, just use --tool-label-pattern= to tell this script
				   the prefix pattern to use for CPU information.
	--sysinfo=str,             str= comma separated values of sysinfo to be collected
	                                available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology

Bench Script: pbench-user-benchmark --help
------------
Usage: pbench-user-benchmark [options] -- <script to run>

	The following options are available:

		-C str --config=str   name of the test config
		--tool-group=str      The tool group to use for the list of tools
		--iteration-list=str  A file containing a list of iterations to run for the provided script;
		                      the file should contain one iteration per line, with a leading
		                      '#' (hash) character used for comments, blank lines are ignored;
		                      each iteration line should use alpha-numeric characters before
		                      the first space to name the iteration, with the rest of the line
		                      provided as arguments to the script;
		                        NOTE: --iteration-list is not compatible with --use-tool-triggers
		--sysinfo=str,[str]   comma separated values of system information to be collected;
		                        available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology
		--pbench-pre=str      path to the script which will be executed before tools are started
		                        NOTE: --pbench-pre is not compatible with --use-tool-triggers
		--pbench-post=str     path to the script which will be executed after tools are stopped and postprocessing is complete
		                        NOTE: --pbench-post is not compatible with --use-tool-triggers
		--use-tool-triggers   use tool triggers instead of normal start/stop around script;
		                        NOTE: --use-tool-triggers is not compatible with --iteration-list,
		                              --pbench-pre, or --pbench-post
		--no-stderr-capture   do not capture stderr of the script to the result.txt file

Bench Script: pbench-user-benchmark --tool-group=bad --sysinfo=bad
------------
	pbench-user-benchmark: invalid --tool-group option ("bad"), directory not found: /var/tmp/pbench-test-bench/pbench-agent/tools-v1-bad
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
	pbench-user-benchmark: invalid --sysinfo option ("bad")

Usage: pbench-user-benchmark [options] -- <script to run>

	The following options are available:

		-C str --config=str   name of the test config
		--tool-group=str      The tool group to use for the list of tools
		--iteration-list=str  A file containing a list of iterations to run for the provided script;
		                      the file should contain one iteration per line, with a leading
		                      '#' (hash) character used for comments, blank lines are ignored;
		                      each iteration line should use alpha-numeric characters before
		                      the first space to name the iteration, with the rest of the line
		                      provided as arguments to the script;
		                        NOTE: --iteration-list is not compatible with --use-tool-triggers
		--sysinfo=str,[str]   comma separated values of system information to be collected;
		                        available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology
		--pbench-pre=str      path to the script which will be executed before tools are started
		                        NOTE: --pbench-pre is not compatible with --use-tool-triggers
		--pbench-post=str     path to the script which will be executed after tools are stopped and postprocessing is complete
		                        NOTE: --pbench-post is not compatible with --use-tool-triggers
		--use-tool-triggers   use tool triggers instead of normal start/stop around script;
		                        NOTE: --use-tool-triggers is not compatible with --iteration-list,
		                              --pbench-pre, or --pbench-post
		--no-stderr-capture   do not capture stderr of the script to the result.txt file

Bench Script: pbench-user-benchmark --bad-to-the-bone
------------
pbench-user-benchmark --bad-to-the-bone

	unrecognized option specified

Usage: pbench-user-benchmark [options] -- <script to run>

	The following options are available:

		-C str --config=str   name of the test config
		--tool-group=str      The tool group to use for the list of tools
		--iteration-list=str  A file containing a list of iterations to run for the provided script;
		                      the file should contain one iteration per line, with a leading
		                      '#' (hash) character used for comments, blank lines are ignored;
		                      each iteration line should use alpha-numeric characters before
		                      the first space to name the iteration, with the rest of the line
		                      provided as arguments to the script;
		                        NOTE: --iteration-list is not compatible with --use-tool-triggers
		--sysinfo=str,[str]   comma separated values of system information to be collected;
		                        available: default, none, all, ara, block, insights, kernel_config, libvirt, security_mitigations, sos, stockpile, topology
		--pbench-pre=str      path to the script which will be executed before tools are started
		                        NOTE: --pbench-pre is not compatible with --use-tool-triggers
		--pbench-post=str     path to the script which will be executed after tools are stopped and postprocessing is complete
		                        NOTE: --pbench-post is not compatible with --use-tool-triggers
		--use-tool-triggers   use tool triggers instead of normal start/stop around script;
		                        NOTE: --use-tool-triggers is not compatible with --iteration-list,
		                              --pbench-pre, or --pbench-post
		--no-stderr-capture   do not capture stderr of the script to the result.txt file
--- Finished test-CL test-benchmark-clis (status=0)
+++ pbench tree state
/var/tmp/pbench-test-bench/pbench-agent
/var/tmp/pbench-test-bench/pbench-agent/pbench.log
/var/tmp/pbench-test-bench/pbench-agent/tmp
/var/tmp/pbench-test-bench/pbench-agent/tools-v1-default
/var/tmp/pbench-test-bench/pbench-agent/tools-v1-default/__trigger__
/var/tmp/pbench-test-bench/pbench-agent/tools-v1-default/testhost.example.com
/var/tmp/pbench-test-bench/pbench-agent/tools-v1-default/testhost.example.com/mpstat
/var/tmp/pbench-test-bench/pbench-agent/tools-v1-default/testhost.example.com/sar
--- pbench tree state
+++ pbench.log file contents
[warn][1900-01-01T00:00:00.000000] pbench-cyclictest is deprecated and will be removed in the next release
[warn][1900-01-01T00:00:00.000000] pbench-cyclictest is deprecated and will be removed in the next release
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
[warn][1900-01-01T00:00:00.000000] pbench-cyclictest is deprecated and will be removed in the next release
[warn][1900-01-01T00:00:00.000000] pbench-dbench is deprecated and will be removed in the next release
[warn][1900-01-01T00:00:00.000000] pbench-dbench is deprecated and will be removed in the next release
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
[warn][1900-01-01T00:00:00.000000] pbench-dbench is deprecated and will be removed in the next release
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
[warn][1900-01-01T00:00:00.000000] pbench-iozone is deprecated and will be removed in the next release
[warn][1900-01-01T00:00:00.000000] pbench-iozone is deprecated and will be removed in the next release
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
[warn][1900-01-01T00:00:00.000000] pbench-iozone is deprecated and will be removed in the next release
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
[warn][1900-01-01T00:00:00.000000] pbench-migrate is deprecated and will be removed in the next release
[warn][1900-01-01T00:00:00.000000] pbench-migrate is deprecated and will be removed in the next release
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
[warn][1900-01-01T00:00:00.000000] pbench-migrate is deprecated and will be removed in the next release
[warn][1900-01-01T00:00:00.000000] pbench-netperf is deprecated and will be removed in the next release
[warn][1900-01-01T00:00:00.000000] pbench-netperf is deprecated and will be removed in the next release
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
[warn][1900-01-01T00:00:00.000000] pbench-netperf is deprecated and will be removed in the next release
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
[error][1900-01-01T00:00:00.000000] invalid sysinfo option, "bad"
--- pbench.log file contents
