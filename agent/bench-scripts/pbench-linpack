#!/bin/bash
# -*- mode: shell-script; indent-tabs-mode: t; sh-basic-offset: 8; sh-indentation: 8; tab-width: 8 -*-

# This is a script to run the linpack benchmark

# TODO:
# 1) add support to run mulitple samples with stddev
# 2) add support for multiple local or remote copies of benchmark running concurrently
# 3) add support for binding copies of benchmark to numa nodes

script_path="$(dirname ${0})"
script_name="$(basename ${0})"
pbench_bin="$(realpath -e ${script_path}/..)"

# source the base script
. "${pbench_bin}"/base

# Every bench-script follows a similar sequence:
# 1) process bench script arguments
# 2) ensure the right version of the benchmark is installed
# 3) gather pre-run state
# 4) run the benchmark and start/stop perf analysis tools
# 5) gather post-run state
# 6) postprocess benchmark data
# 7) postprocess analysis tool data

export benchmark="linpack"

# Defaults
def_threads=$(cat /proc/cpuinfo | grep processor | wc -l)
threads=${def_threads}
def_nr_samples=2
nr_samples=${def_nr_samples}
orig_cmd="${*}"
tool_group="default"
export config=""
sysinfo="default"
clients="localhost"

function usage {
	printf "\tThe following options are available:\n\n"
	printf -- "\t-C str --config=str         name of the test config\n"
	printf -- "\t-c str[,str...] --clients=str[,str...]      a list of one or more host names (hosta,hostb,hostc) where you want ${script_name} to run\n"
	printf -- "\t       --samples=<int>      number of samples to use per test iteration (default is ${def_nr_samples})\n"
	printf -- "\t       --threads=int[,int]  number of threads to use (default is # local CPUs)\n"
	printf -- "\t       --tool-group=str\n"
	printf -- "\t       --sysinfo=str,       str= comma separated values of sysinfo to be collected\n"
	printf -- "\t                                available: $(pbench-display-sysinfo-options)\n"
}

# Process options and arguments
opts=$(getopt -q -o C:c:h --longoptions "config:,clients:,samples:,threads:,tool-group:,sysinfo:,help" -n "getopt.sh" -- "${@}")
if [[ ${?} -ne 0 ]]; then
	printf -- "${script_name} ${*}\n"
	printf -- "\n"
	printf -- "\tunrecognized option specified\n\n"
	usage
	exit 1
fi
eval set -- "${opts}"
while true; do
	arg=${1}
	shift
	case "${arg}" in
	-c|--config)
		if [[ -n "${1}" ]]; then
			config="${1}"
			shift;
		fi
		;;
	-c|--clients)
		if [[ -n "${1}" ]]; then
			clients="${1}"
			shift;
		fi
		;;
	--samples)
		if [[ -n "${1}" ]]; then
			nr_samples="${1}"
			shift;
		fi
		;;
	--threads)
		if [[ -n "${1}" ]]; then
			threads="${1}"
			shift;
		fi
		;;
	--tool-group)
		if [[ -n "${1}" ]]; then
			tool_group="${1}"
			shift;
		fi
		;;
	--sysinfo)
		if [[ -n "${1}" ]]; then
			sysinfo="${1}"
			shift;
		fi
		;;
	-h|--help)
		usage
		exit 0
		;;
	--)
		shift;
		break;
		;;
	*)
		echo "what happened? [${1}]" >&2
		exit 1
		;;
	esac
done
verify_common_bench_script_options ${tool_group} ${sysinfo}

ver="$(pbench-config version ${benchmark})"
if [[ -z "${ver}" ]]; then
	error_log "${script_name}: package version is missing in config file"
	exit 1
fi
if [[ -z "${linpack_dir}" ]]; then
	linpack_dir="/usr/local/${script_name}-${ver}/benchmarks/linpack"
	linpack_dir_kind="default"
else
	linpack_dir_kind="provided"
fi
if [[ ! -d "${linpack_dir}" ]]; then
	error_log "${script_name}: the ${linpack_dir_kind} linpack directory, ${linpack_dir}, does not exist"
	exit 1
fi
linpack_cmd="${linpack_dir}/xlinpack_xeon64"
if [[ ! -x "${linpack_cmd}" ]]; then
	error_log "${script_name}: the expected linpack command, ${linpack_cmd}, does not exist"
	exit 1
fi

function store_and_run {
	local workdir=${1}
	local cmd=${2}
	local filename=${3}
	(
		cd "${workdir}" &&
		echo "${cmd}" > "${filename}" &&
		chmod +x "${filename}" &&
		"./${filename}" &> "${filename}.out"
	)
	ret=${?}
	if [[ ${ret} -ne 0 ]]; then
		warn_log "failed to execute: ${workdir}/${filename}"
	fi
	return ${ret}
}

function preprocess-iteration {
	local _cmd="${pbench_bin}/bench-scripts/postprocess/linpack-prepare-input-file"
	store_and_run "${1}" "'${_cmd}' --output-dir '${1}' --threads '${2}' --run-samples 1 --linpack-binary '${linpack_cmd}'" "${benchmark}-preprocess.cmd"
}

function postprocess-iteration {
	local _cmd="${pbench_bin}/bench-scripts/postprocess/linpack-postprocess-cdm"
	store_and_run "${1}" "'${_cmd}' '${1}' '${2}' '${tool_group}' 1 html" \
			"${benchmark}-postprocess.cmd"
}

function postprocess-results {
	local _cmd="${pbench_bin}/bench-scripts/postprocess/generate-benchmark-summary"
	store_and_run "${1}" "'${_cmd}' '${benchmark}' '${orig_cmd}' '${1}'" \
			"generate-benchmark-summary.cmd"
}

benchmark_fullname="${benchmark}_${config}_${date_suffix}"
export benchmark_run_dir="${pbench_run}/${benchmark_fullname}"

# we'll record the iterations in this file
benchmark_iterations="${benchmark_run_dir}/.iterations"
mdlog=${benchmark_run_dir}/metadata.log

function record_iteration {
	local count=${1}
	local thread=${2}
	local iteration=${3}

	echo ${iteration} >> ${benchmark_iterations}
	echo ${count} | pbench-add-metalog-option ${mdlog} iterations/${iteration} iteration_number
	echo ${thread} | pbench-add-metalog-option ${mdlog} iterations/${iteration} threads
	echo ${iteration} | pbench-add-metalog-option ${mdlog} iterations/${iteration} iteration_name
}


mkdir -p ${benchmark_run_dir}/.running

# now that the benchmark_run_dir directory exists, we can initialize the iterations file
> ${benchmark_iterations}

# Start the tool meisters on each registered local/remote host
pbench-tool-meister-start --sysinfo="${sysinfo}" "${tool_group}"
if [[ ${?} != 0 ]]; then
	error_log "[${script_name}]: failed to start the tool meisters."
	exit 1
fi

trap "interrupt" INT QUIT TERM

let count=1
for thread in ${threads//,/ }; do
	iteration="${count}-${thread}-threads"
	iteration_dir="${benchmark_run_dir}/${iteration}"
	mkdir -p "${iteration_dir}"
	record_iteration ${count} ${thread} ${iteration}
	echo "Starting iteration ${iteration}"
	# Pre-processing: generate the linpack input files
	preprocess-iteration "${iteration_dir}" "${thread}"
	# Distribute the linpack input files to remote clients if necessary
	for client in ${clients//,/ }; do
		if ! pbench-is-local "${client}"; then
			ssh ${ssh_opts} "${client}" "mkdir -p '${iteration_dir}'"
			scp ${scp_opts} "${iteration_dir}/"linpack* "${client}:${iteration_dir}"
		fi
	done

	for sample in $(seq 1 ${nr_samples}); do
		echo "test sample ${sample} of ${nr_samples}"
		sample_dir="${iteration_dir}/sample${sample}"

		# Run the benchmark and start/stop perf analysis tools
		pbench-start-tools --group=${tool_group} --dir="${sample_dir}"

		for client in ${clients//,/ }; do
			if pbench-is-local "${client}"; then
				\rm -f "${iteration_dir}/linpack.finished"
				( cd "${iteration_dir}" && screen -dmS pbench-linpack ./linpack.sh )
			else
				ssh ${ssh_opts} ${client} "cd '${iteration_dir}' && \rm -f linpack.finished && screen -dmS pbench-linpack './linpack.sh'"
			fi
		done

		# Wait for all of them to finish
		echo "Waiting for all clients to finish pbench-linpack jobs"
		for client in ${clients//,/ }; do
			if pbench-is-local "${client}"; then
				while ! [ -e "${iteration_dir}/linpack.finished" ]; do
					sleep 1
				done
			else
				ssh ${ssh_opts} ${client} "while ! [ -e '${iteration_dir}/linpack.finished' ]; do sleep 1; done"
			fi
			echo "Iteration finished on ${client}"
		done

		pbench-stop-tools --group=${tool_group} --dir="${sample_dir}"

		# Move the results to the output directory expected by the postprocess script
		for client in ${clients//,/ }; do
			client_result_dir="${sample_dir}/clients/${client}"
			mkdir -p "${client_result_dir}"
			if pbench-is-local "${client}"; then
				mv "${iteration_dir}/"linpack.{out,meta} "${client_result_dir}"
			else
				scp ${scp_opts} "${client}:${iteration_dir}"/linpack.{out,meta} "${client_result_dir}"
			fi
		done

		# Have the Tool Meisters send the tool data back and post-process it
		pbench-send-tools --group=${tool_group} --dir="${sample_dir}"
		pbench-postprocess-tools --group=${tool_group} --dir="${sample_dir}"

		# Post-process the benchmark results after the tools so that the
		# post-processing has that data available to it.
		postprocess-iteration "${sample_dir}" "${benchmark_run_dir}"
	done

	echo "Iteration ${iteration} complete"
	let count++
done
postprocess-results "${benchmark_run_dir}"

# Stop the tool meisters on each registered local/remote host
pbench-tool-meister-stop --sysinfo="${sysinfo}" "${tool_group}"
if [[ ${?} != 0 ]]; then
	error_log "[${script_name}]: failed to stop the tool meisters."
fi

rmdir ${benchmark_run_dir}/.running
