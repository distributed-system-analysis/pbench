#!/bin/bash
# -*- mode: shell-script; indent-tabs-mode: t; sh-basic-offset: 8; sh-indentation: 8; sh-indent-for-case-alt: + -*-

# This is a script to run the linpack benchmark

# TODO:
# 1) write results in pbench standard file names and formats
# 2) add support to run mulitple samples and get stddev
# 3) add support for multiple local or remote copies of benchmark running concurrently
# 4) add support for binding copies of benchmark to numa nodes

script_path=`dirname $0`
script_name=`basename $0`
pbench_bin="`cd ${script_path}/..; /bin/pwd`"

# source the base script
. "$pbench_bin"/base

benchmark_rpm=$script_name
export benchmark="linpack"
ver=11.1.3
linpack_dir=/usr/local/${script_name}-${ver}/benchmarks/linpack
linpack_cmd=xlinpack_xeon64
linpack_dat=linpack.dat
threads=`cat /proc/cpuinfo | grep processor | wc -l`


# Every bench-script follows a similar sequence:
# 1) process bench script arguments
# 2) ensure the right version of the benchmark is installed
# 3) gather pre-run state
# 4) run the benchmark and start/stop perf analysis tools
# 5) gather post-run state
# 6) postprocess benchmark data
# 7) postprocess analysis tool data

# Defaults
baseconfig="`uname -r`"
start_iteration_num=1
orig_cmd="$*"
tool_group="default"
export config=""
sysinfo="default"

function usage {
	printf "\tThe following options are available:\n\n"
	printf -- "\t-C str --config=str         name of the test config\n"
	printf -- "\t       --threads=int[,int]  number of threads to use (default is num_cpus)\n"
	printf -- "\t       --tool-group=str\n"
	printf -- "\t       --sysinfo=str,       str= comma separated values of sysinfo to be collected\n"
	printf -- "\t                                available: $(pbench-display-sysinfo-options)\n"
}

# Process options and arguments
opts=$(getopt -q -o C:h --longoptions "config:,threads:,tool-group:,sysinfo:,help" -n "getopt.sh" -- "$@");
if [ $? -ne 0 ]; then
	printf -- "${script_name} $*\n"
	printf -- "\n"
	printf -- "\tunrecognized option specified\n\n"
	usage
	exit 1
fi
eval set -- "$opts";
while true; do
	case "$1" in
		-c|--config)
		shift;
		if [ -n "$1" ]; then
			config="$1"
			shift;
		fi
		;;
		--threads)
		shift;
		if [ -n "$1" ]; then
			threads="$1"
			shift;
		fi
		;;
		--tool-group)
		shift;
		if [ -n "$1" ]; then
			tool_group="$1"
			shift;
		fi
		;;
		--sysinfo)
		shift;
		if [ -n "$1" ]; then
			sysinfo="$1"
			shift;
		fi
		;;
		-h|--help)
		usage
		exit 0
		;;
		--)
		shift;
		break;
		;;
		*)
		echo "what happened? [$1]"
		exit 0
		break;
		;;
	esac
done
verify_common_bench_script_options $tool_group $sysinfo

function store_and_run {
	workdir="$1"
	cmd="$2"
	filename="$3"
	(
		cd "$1" &&
		echo "$cmd" > "$filename" &&
		chmod +x "$filename" &&
		"./$filename" &> "$filename.out"
	)
	ret=$?
	if [ $ret -ne 0 ]; then
		debug_log "failed to execute: $workdir/$filename"
	fi
	return $ret
}

function postprocess-iteration {
	# First move our results to the expected location
	mkdir -p "$1/clients/localhost"
	cp "$1/result.txt" "$1/clients/localhost/linpack.out"
	# Now run the linpack-postprocess-cdm
	local _cmd="$pbench_bin/bench-scripts/postprocess/linpack-postprocess-cdm"
	store_and_run "$1" "'$_cmd' '$1' '$2' '$tool_group' 1 html" \
			"$benchmark-postprocess.cmd"
}

function postprocess-results {
	local _cmd="$pbench_bin/bench-scripts/postprocess/generate-benchmark-summary"
	store_and_run "$1" "'$_cmd' '$benchmark' '$orig_cmd' '$1'" \
			"generate-benchmark-summary.cmd"
}

## Ensure the right version of the benchmark is installed
check_install_rpm "${benchmark_rpm}" "${ver}"

benchmark_fullname="${benchmark}_${config}_${date_suffix}"
export benchmark_run_dir="$pbench_run/${benchmark_fullname}"
benchmark_summary_txt_file="$benchmark_run_dir/$benchmark-summary.txt"
benchmark_summary_html_file="$benchmark_run_dir/$benchmark-summary.html"
benchmark_iterations="${benchmark_run_dir}/.iterations"

mkdir -p ${benchmark_run_dir}/.running

# now that the benchmark_run_dir directory exists, we can initialize the iterations file
> ${benchmark_iterations}

iteration=1-$threads-threads
sample="sample1"
echo $iteration >> $benchmark_iterations
benchmark_results_dir="$benchmark_run_dir/$iteration/${sample}"
result_file=$benchmark_results_dir/result.txt
mkdir -p $benchmark_results_dir

# Start the tool meisters on each registered local/remote host
pbench-tool-meister-start --sysinfo="${sysinfo}" "${tool_group}"
if [[ ${?} != 0 ]]; then
	error_log "[${script_name}]: failed to start the tool meisters."
	exit 1
fi

trap "interrupt" INT QUIT TERM

## Run the benchmark and start/stop perf analysis tools
echo "Starting iteration 1 (1 of 1)"
pbench-start-tools --group=$tool_group --dir=$benchmark_results_dir

echo "test sample 1 of 1"
OMP_NUM_THREADS=$threads ${linpack_dir}/${linpack_cmd} < ${linpack_dir}/${linpack_dat} | tee $result_file

pbench-stop-tools --group=$tool_group --dir=$benchmark_results_dir
pbench-send-tools --group=$tool_group --dir=$benchmark_results_dir
pbench-postprocess-tools --group=$tool_group --dir=$benchmark_results_dir
postprocess-iteration "$benchmark_results_dir" "$benchmark_run_dir"
echo "Iteration 1 complete (1 of 1 iterations)"
postprocess-results "$benchmark_run_dir"

ln -s ${sample} $benchmark_run_dir/$iteration/reference-result

# Stop the tool meisters on each registered local/remote host
pbench-tool-meister-stop --sysinfo="${sysinfo}" "${tool_group}"
if [[ ${?} != 0 ]]; then
	error_log "[${script_name}]: failed to stop the tool meisters."
fi

rmdir $benchmark_run_dir/.running
