#!/bin/bash
# -*- mode: shell-script; indent-tabs-mode: t; sh-basic-offset: 8; sh-indentation: 8; sh-indent-for-case-alt: + -*-

# This is a script to run the fio benchmark

script_path=`dirname $0`
script_name=`basename $0`
pbench_bin="`cd ${script_path}/..; /bin/pwd`"

# source the base script
. "$pbench_bin"/base

benchmark_rpm=$script_name
benchmark="fio"
export benchmark_run_dir=""
# allow unit tests to override
if [[ -z "$benchmark_bin" ]]; then
	benchmark_bin=/usr/local/bin/$benchmark
fi	
ver=$(getconf.py version pbench-fio)
if [ -z "$ver" ] ;then
	echo "pbench-fio: package version is missing in config file" > /dev/tty
	exit 1
fi

job_file="${script_path}/templates/fio.job"

# Every bench-script follows a similar sequence:
# 1) process bench script arguments
# 2) ensure the right version of the benchmark is installed
# 3) gather pre-run state
# 4) run the benchmark and start/stop perf analysis tools
# 5) gather post-run state
# 6) postprocess benchmark data
# 7) postprocess analysis tool data

orig_cmd="$*"

# Defaults
keep_failed_tool_data="y"
tar_nonref_data="y"
postprocess_only="n"
nr_samples=5
maxstddevpct=5 # maximum allowable standard deviation in percent
max_failures=6 # after N failed attempts to hit below $maxstddevpct, move on to the nest test
supported_test_types="read,write,rw,randread,randwrite,randrw"
install_only="n"
remote_only="n"
config=""
rate_iops=""
test_types="read,randread"		# default is -non- destructive
block_sizes="4,64,1024"
targets="/tmp/fio"
directory=""
numjobs=""
runtime=""
ramptime=""
iodepth=""
ioengine=""
pre_iteration_script=""
job_mode="concurrent" # serial or concurrent
file_size=""
direct="" # don't cache IO's by default
sync="" # don't sync IO's by default
clients="" # A list of hostnames (hosta,hostb,hostc) where you want fio to run.  Note: if you use this, pbench must be installed on these systems already.
client_file="" # A file containing a list of hostnames
tool_label_pattern="fio-"
tool_group="default"
max_key_length=20
primary_metric="readwrite_IOPS"
histogram_interval_msec=$(getconf.py histogram-interval-msec pbench-fio)
if [ -z "$histogram_interval_msec" ] ;then
	histogram_interval_msec=10000
fi
sysinfo="default"

function fio_usage() {
		printf "The following options are available:\n"
		printf "\n"
		printf -- "\t-t str[,str] --test-types=str[,str]\n"
		printf "\t\tone or more of %s\n" $supported_test_types
		printf "\n"
		printf -- "\t--direct=[0/1]\n"
		printf "\t\t1 = O_DIRECT enabled (default), 0 = O_DIRECT disabled\n"
		printf "\n"
		printf -- "\t--sync=[0/1]\n"
		printf "\t\t1 = O_SYNC enabled, 0 = O_SYNC disabled (defalt)\n"
		printf "\n"
		printf -- "\t--rate-iops=int\n"
		printf "\t\tdo not exceeed this IOP rate (per job, per client)\n"
		printf "\n"
		printf -- "\t-r int --runtime=int\n"
		printf "\t\truntime in seconds (default is $runtime)\n"
		printf "\n"
		printf -- "\t--ramptime=int\n"
		printf "\t\ttime in seconds to warm up test before taking measurements (default is $ramptime)\n"
		printf "\n"
		printf -- "\t-b int[,int] --block-sizes=str[,str] (default is $block_sizes)\n"
		printf "\t\tone or more block sizes in KiB (default is $block_sizes)\n"
		printf "\n"
		printf -- "\t-s int[,int] --file-size=str[,str] (default is $file_size)\n"
		printf "\t\tfile sizes in MiB: %s\n"
		printf "\n"
		printf -- "\t-d str[,str] --targets=str[,str]\n"
		printf "\t\tone or more directories or block devices (default is $targets)\n"
		printf "\t\t(persistent names for devices highly recommended)\n"
		printf "\n"
		printf -- "\t-j str --job-mode=str    str=[serial|concurrent]  (default is $job_mode)\n"
		printf "\n"
		printf -- "\t--ioengine=str           str= any ioengine fio supports (default is $ioengine)\n"
		printf "\n"
		printf -- "\t--iodepth=<int>"
		printf "\t\tSet the iodepth config variable in the fio job file\n"
		printf "\n"
		printf -- "\t-c str[,str] --clients=str[,str]      str= one or more remote systems to run fio\n"
		printf -- "\t                         If no clients are specified, fio is run locally\n"
		printf -- "\t--client-file=str        str= file (with absolute path) which contains 1 client per line\n"

		printf -- "\t--config=str\n"
		printf "\t\tname of the test configuration\n"
		printf "\n"
		printf -- "\t--tool-group=str\n"
		printf "\n"
		printf -- "\t--postprocess-only=[y|n]\n"
		printf "\t\tuse this only if you want to postprocess an existing result again\n"
		printf "\t\tyou must use --run-dir option with this\n"
		printf "\n"
		printf -- "\t--run-dir=<path>\n"
		printf "\t\tprovide the path of an existig result (typically somewhere in $pbench_run\n"
		printf -- "\t--directory=<path>\n"
		printf "\t\tprovide the path to an existing directory where fio operations will be performed\n"
		printf -- "\t--numjobs=<int>\n"
		printf "\t\tnumber of jobs to run, if not given then fio default of numjobs=1 will be used\n"
		printf -- "\t--job-file=<path>\n"
		printf "\t\tprovide the path of a fio job config file, (default is $job_file)\n"
		printf -- "\t--pre-iteration-script=str\n"
		printf -- "\t\tuse executable script/program to prepare the system for test iteration\n"
		printf -- "\t\texample: --pre-iteration-script=\$HOME/drop-cache.sh\n"
		printf -- "\t--samples=<int>\n"
		printf "\t\tnumber of samples to use per test iteration (default is $nr_samples)\n"
		printf -- "\t--max-stddev=<int>\n"
		printf "\t\tthe maximum percent stddev allowed to pass\n"
		printf -- "\t--max-failures=<int>\n"
		printf "\t\tthe maximum number of failures to get below stddev\n"
		printf -- "\t--install\n"
		printf "\t\tinstall only\n"
		printf "\t\tDefault is n\n"
		printf -- "\t--remote-only\n"
		printf "\trun this on the remotes only\n"
		printf "\t--histogram-interval-msec=<int>\n"
		printf "\tset the histogram logging interval in milliseconds (default $histogram_interval_msec)\n"
		printf -- "\t--sysinfo=str            str= comma seperated values of sysinfo to be collected\n"
		printf -- "\t                              available: $(pbench-collect-sysinfo --options)\n"
}

function fio_process_options() {
	opts=$(getopt -q -o jic:t:b:s:d:r: --longoptions "help,max-stddev:,max-failures:,samples:,direct:,sync:,install,remote-only,clients:,client-file:,iodepth:,ioengine:,config:,jobs-per-dev:,job-mode:,rate-iops:,ramptime:,runtime:,test-types:,block-sizes:,file-size:,targets:,tool-group:,postprocess-only:,run-dir:,directory:,numjobs:,job-file:,sysinfo:,pre-iteration-script:,histogram-interval-msec:" -n "getopt.sh" -- "$@");

	if [ $? -ne 0 ]; then
		printf "\t${benchmark}: you specified an invalid option\n\n"
		fio_usage
		exit 1
	fi
	eval set -- "$opts";
	while true; do
		case "$1" in
			--help)
			fio_usage
			exit
			;;
			--install)
			shift;
			install_only="y"
			;;
			--remote-only)
			shift;
			remote_only="y"
			;;
			--max-stddev)
			shift;
			if [ -n "$1" ]; then
				maxstddevpct="$1"
				shift;
			fi
			;;
			--max-failures)
			shift;
			if [ -n "$1" ]; then
				max_failures="$1"
				shift;
			fi
			;;
			--samples)
			shift;
			if [ -n "$1" ]; then
				nr_samples="$1"
				shift;
			fi
			;;
			--direct)
			shift;
			if [ -n "$1" ]; then
				direct=$1
				shift;
			fi
			;;
			--sync)
			shift;
			if [ -n "$1" ]; then
				sync=$1
				shift;
			fi
			;;
			-t|--test-types)
			shift;
			if [ -n "$1" ]; then
				test_types="$1"
				shift;
			fi
			;;
			-b|--block-sizes)
			shift;
			if [ -n "$1" ]; then
				block_sizes="$1"
				shift;
			fi
			;;
			-s|--file-size)
			shift;
			if [ -n "$1" ]; then
				file_size="$1"
				shift;
			fi
			;;
			--ramptime)
			shift;
			if [ -n "$1" ]; then
				ramptime="$1"
				shift;
			fi
			;;
			--rate-iops)
			shift;
			if [ -n "$1" ]; then
				rate_iops="$1"
				shift;
			fi
			;;
			-r|--runtime)
			shift;
			if [ -n "$1" ]; then
				runtime="$1"
				shift;
			fi
			;;
			-c|--clients)
			shift;
			if [ ! -z "$client_file" ] ;then
				printf "--clients and --client-file are mutually exclusive"
				exit 1
			fi
			if [ -n "$1" ]; then
				clients="$1"
				shift;
			fi
			;;
			--client-file)
			shift;
			if [ ! -z "$clients" ] ;then
				printf "--clients and --client-file are mutually exclusive"
				exit 1
			fi
			if [ -n "$1" ]; then
				if [ -e $1 ]; then
					client_file=$1
					if [[ "$client_file" != /* ]] ;then
						# make it absolute
						client_file=$PWD/$client_file
					fi
					while read line; do
						clients="$clients,$line"
					done <$1
					clients=`echo $clients | sed -e 's/^,//'`
				fi
				shift;
			fi
			;;
			-d|--targets)
			shift;
			if [ -n "$1" ]; then
				targets="$1"
				shift;
			fi
			;;
			-j|--job-mode)
			shift;
			if [ -n "$1" ]; then
				job_mode="$1"
				shift;
			fi
			;;
			--config)
			shift;
			if [ -n "$1" ]; then
				config="$1"
				shift;
			fi
			;;
			--ioengine)
			shift;
			if [ -n "$1" ]; then
				ioengine="$1"
				shift;
			fi
			;;
			--iodepth)
			shift;
			if [ -n "$1" ]; then
				iodepth="$1"
				shift;
			fi
			;;
			--tool-group)
			shift;
			if [ -n "$1" ]; then
				tool_group="$1"
				shift;
			fi
			;;
			--postprocess-only)
			shift;
			if [ -n "$1" ]; then
				postprocess_only="$1"
				shift;
			fi
			;;
			--run-dir)
			shift;
			if [ -n "$1" ]; then
				run_dir="$1"
				shift;
			fi
			;;
			--directory)
			shift;
			if [ -n "$1" ]; then 
				directory="$1"
				shift;
			fi
			;; 
			--numjobs)
			shift;
			if [ -n "$1" ]; then
				numjobs="$1"
				shift;
			fi 
			;;
			--job-file)
			shift;
			if [ -n "$1" ]; then
				job_file="$1"
				shift;

			fi
			;;
			--pre-iteration-script)
			shift;
			if [ -n "$1" ]; then
				pre_iteration_script="$1"
				if [ ! -x $pre_iteration_script ]; then
					printf "ERROR: $pre_iteration_script must be executable\n"
					exit 1
				fi
				shift;
			fi
			;;
			--histogram-interval-msec)
			shift;
			histogram_interval_msec="$1"
			shift
			;;
			--sysinfo)
			shift;
			if [ -n "$1" ]; then
				sysinfo="$1"
				shift;
                	fi
			;;
			--)
			shift;
			break;
			;;
			*)
			echo "what's this? [$1]"
			shift;
			break;
			;;
		esac
	done
	pbench-collect-sysinfo --sysinfo=$sysinfo --check
	if [ $? != 0 ]; then
		printf -- "$*\n\n"
		printf "\t${benchmark}: you specified an invalid --sysinfo option (\"$sysinfo\")\n\n"
		fio_usage
	exit 1
	fi
	if [ "$postprocess_only" = "n" ]; then
		benchmark_fullname="${benchmark}_${config}_${date_suffix}"
		benchmark_run_dir="$pbench_run/${benchmark_fullname}"
	else
		if [ -z "$run_dir" ]; then
			err_log "I need a directory if postprocessing an existing result (--run-dir=)"
			exit 1
		fi
		benchmark_fullname="$(basename $run_dir)"
		benchmark_run_dir="$run_dir"
	fi
	benchmark_iterations="$pbench_tmp/${benchmark_fullname}.iterations"
	> ${benchmark_iterations}

	verify_tool_group $tool_group
}

function record_iteration {
	local count=$1
	local test_type=$2
	local block_size=$3
	local iteration=$4

	mdlog=${benchmark_run_dir}/metadata.log
	echo ${iteration} >> ${benchmark_iterations}
	echo $count | pbench-add-metalog-option ${mdlog} iterations/${iteration} iteration_number
	echo $test_type | pbench-add-metalog-option ${mdlog} iterations/${iteration} test_type
	echo $block_size | pbench-add-metalog-option ${mdlog} iterations/${iteration} block_size_KiB
	echo $iteration | pbench-add-metalog-option ${mdlog} iterations/${iteration} iteration_name
}


# Ensure the right version of the benchmark is installed
function fio_install() {
	if [ "$postprocess_only" = "n" ]; then
		if check_install_rpm $benchmark_rpm $ver; then
			debug_log "[$script_name]$benchmark_rpm $ver is installed"
		else
			debug_log "[$script_name]$benchmark_rpm $ver installation failed, exiting"
			exit 1
		fi
                
	fi
	if [ ! -z "$clients" ] ; then
		debug_log "verifying clients have fio installed"
		echo "verifying clients have fio installed"
		for client in `echo $clients | sed -e s/,/" "/g`; do
			ssh $ssh_opts $client ${pbench_install_dir}/bench-scripts/$script_name --remote-only --install &
		done
		wait
	fi
}

# install python-pandas on the controller: fiologparser_hist.py needs it
function pandas_install() {
	if [ "$postprocess_only" = "n" ]; then
		pandas_pkg=$(getconf.py pandas-package packages)
		if [[ -z ${pandas_pkg} ]] ;then
			return 1
		fi
		# args 2 and 3 used in unit tests only.
		if check_install_rpm ${pandas_pkg} "" python-pandas; then
			debug_log "[$script_name]python-pandas is installed"
		else
			debug_log "[$script_name]python-pandas installation failed, exiting."
                    	debug_log "[$script_name]On RHEL, python-pandas is in the EPEL repo."
                    	debug_log "[$script_name]See https://fedoraproject.org/wiki/EPEL for details."
			exit 1
		fi
	fi
}

# Make sure this devices exists
function fio_device_check() {
	local devs=$1
	local clients=$2
	local dev=""
	local client=""
	local rc=0
	if [ "$postprocess_only" = "n" ]; then
		debug_log "fio_device_check() $devs $clients"
		for dev in `echo $devs | sed -e s/,/" "/g`; do
			if echo $dev | grep -q "^/dev/"; then
				if [ ! -z "$clients" ]; then
					for client in `echo $clients | sed -e s/,/" "/g`; do
						debug_log "checking to see if $dev exists on client $client"
						ssh $ssh_opts $client "if [ -L $dev ]; then dev=`dirname $dev`/`readlink $dev`; fi; test -b $dev" || rc=1
					done
					wait
				else
					if [ -L $dev ]; then dev=`dirname $dev`/`readlink $dev`; fi; test -b $dev || rc=1
				fi
				if [ $rc -eq 1 ]; then
					debug_log "At least one client did not have block device $dev, exiting"
					exit 1
				fi
			fi
		done
	fi
}

function fio_create_jobfile() {
	local fio_job_file="${13}"

	mkdir -p "`dirname \"$fio_job_file\"`"
	"${script_path}/templates/make-fio-jobfile.py" -j $job_file \
		-bs="`printf \"%sk\" $3`" -rw="$1" \
		-ioengine="$2" \
		-iodepth="$4" \
		-direct="$5" \
		-sync="$6" \
		-runtime="$7" \
		-ramptime="$8" \
		-size="$9" \
		-rate_iops="${10}" \
		-log_hist_msec="${11}" \
		-numjobs="${14}" \
		-targets $(echo "${12}" | sed -e 's/,/ /g') \
		| sed -e 's/ = /=/g' > $fio_job_file

	if [ $? -ne 0 ]; then
		debug_log "Failed to create jobfile $fio_job_file."
		exit 1
	fi
	echo "The following jobfile was created: $fio_job_file"
	cat $fio_job_file
}

function fio_run_job() {
	local iteration="$1"
	local benchmark_results_dir="$2"
	local fio_job_file="$3"
	local clients="$4"
	local bench_cmd="$benchmark_bin"
	local bench_opts="--output-format=json $fio_job_file"

	if [ ! -e $fio_job_file ]; then
		debug_log "fio jobfile could not be found: $fio_job_file"
		return
	fi
	echo "running fio job: $fio_job_file"

	mkdir -p $benchmark_results_dir
	mkdir -p $benchmark_results_dir/clients
	if [ ! -z "$clients" ]; then
		debug_log "creating directories on the clients"
		for client in `echo $clients | sed -e s/,/" "/g`; do
			ssh $ssh_opts $client mkdir -p $benchmark_results_dir &
		done
		wait
		debug_log "opening port 8765 on firewall on the clients"
		for client in `echo $clients | sed -e s/,/" "/g`; do
			ssh $ssh_opts $client "firewall-cmd --add-port=8765/tcp >/dev/null" &
		done
		wait
		debug_log "killing any old fio process on the clients"
		for client in `echo $clients | sed -e s/,/" "/g`; do
			ssh $ssh_opts $client "killall fio >/dev/null 2>&1" &
		done
		wait
		debug_log "starting new fio process on the clients"
		for client in `echo $clients | sed -e s/,/" "/g`; do
			ssh $ssh_opts $client "pushd $benchmark_results_dir >/dev/null; screen -dmS fio-server bash -c ''$bench_cmd' --server 2>&1 >client-result.txt'"
		done
		wait
	else
		mkdir -p $benchmark_results_dir/clients/localhost
	fi

	# certain test preparation steps such as cache dropping 
	# can be a bit hard on the system, give it a few
	# seconds before actually starting test
	# by putting this before pbench-start-tools, 

	if [ -n "$pre_iteration_script" ] ; then
		printf "running pre-iteration-script command: $pre_iteration_script\n"
		eval "$pre_iteration_script"
	fi
	pbench-start-tools --group=$tool_group --iteration=$iteration --dir=$benchmark_results_dir
	local client_opts=""

	if [ ! -z "$client_file" ] ;then
		typeset -i nclients=$(wc -l $client_file | cut -d ' ' -f 1)
		client_opts="--client=$client_file --max-jobs=$nclients"
	elif [ ! -z "$clients" ]; then
		local max_jobs=0
		for client in `echo $clients | sed -e s/,/" "/g`; do
			client_opts="$client_opts --client=$client"
			if [ ! -z $numjobs ]; then 
				let max_jobs=$numjobs
			else
				let max_jobs=$max_jobs+1
			fi 
		done
		client_opts="$client_opts --max-jobs=$max_jobs"
	fi
	
	# create a command file and keep it with the results for debugging later, or user can run outside of pbench
	echo "$bench_cmd $client_opts $bench_opts" >$benchmark_results_dir/fio.cmd
	chmod +x $benchmark_results_dir/fio.cmd
	debug_log "$benchmark: Going to run [$bench_cmd $bench_opts $client_opts]"
	pushd $benchmark_results_dir >/dev/null
	$benchmark_results_dir/fio.cmd >$benchmark_results_dir/fio-result.txt
	popd >/dev/null
	pbench-stop-tools --group=$tool_group --iteration=$iteration --dir=$benchmark_results_dir
	if [ ! -z "$clients" ]; then
		for client in `echo $clients | sed -e s/,/" "/g`; do
			mkdir -p $benchmark_results_dir/clients/$client
			/bin/mv $benchmark_results_dir/*.log.$client $benchmark_results_dir/clients/$client/
			# remove the trialing client name in the log files
			pushd $benchmark_results_dir/clients/$client >/dev/null
			for i in `/bin/ls | grep log`; do
				mv $i `echo $i | sed -e s/\.$client//`
			done
			# Process the histograms
			# Determine histogram interval based on value used in job file.
			#my $log_interval = `cat $dir/fio.job | grep "^log_hist_msec"`;
			#if [ ! $log_interval =~ /^\s*$/ ]; then
			if grep -q "^log_hist_msec" $fio_job_file; then
                		mkdir -p $benchmark_results_dir/clients/$client/hist
				# fiologparser_hist needs the polling interval to do its job,
				# it gets that from the job file containing log_hist_msec parameter
                		fiologparser_hist.py --job-file=$benchmark_results_dir/fio.job $benchmark_results_dir/clients/$client/fio_clat_hist.*.log* >$benchmark_results_dir/clients/$client/hist/hist.csv
                		#if [ -e $benchmark_results_dir/clients/$client/hist/hist.csv ]; then
					$script_path/postprocess/$benchmark-postprocess-viz.py --job-file=$fio_job_file $benchmark_results_dir/clients/$client/hist
				#fi
			fi
			popd >/dev/null
		done
	else
		/bin/mv $benchmark_results_dir/*.log $benchmark_results_dir/clients/localhost/
	fi
	pbench-postprocess-tools --group=$tool_group --iteration=$iteration --dir=$benchmark_results_dir
	echo "fio job complete"
}


# Run the benchmark and start/stop perf analysis tools
function fio_run_benchmark() {
	fio_device_check "$targets" "$clients"

	mkdir -p $benchmark_run_dir/.running
	local count=1
	if [ "$job_mode" = "serial" ]; then
		# if each target is separated by a space, there will be one job for each in next for loop
		targets=`echo $targets | sed -e s/,/" "/g`
	fi
	typeset -i ntargets=$(echo $targets | wc -w)
	typeset -i ntesttypes=$(echo $test_types | sed -e 's/,/ /g' | wc -w)
	typeset -i nblocksizes=$(echo $block_sizes | sed -e 's/,/ /g' | wc -w)
	typeset -i total_iterations=$ntargets*$ntesttypes*$nblocksizes
	for dev in $targets; do
		for test_type in `echo $test_types | sed -e s/,/" "/g`; do
			for block_size in `echo $block_sizes | sed -e s/,/" "/g`; do
				job_num=1
				iteration="${count}-${test_type}-${block_size}KiB"
				record_iteration ${count} ${test_type} ${block_size} ${iteration}
				iteration_dir=$benchmark_run_dir/$iteration
				result_stddevpct=$maxstddevpct # this test case will get a "do-over" if the stddev is not low enough
				failures=0
				while [[ $(echo "if (${result_stddevpct} >= ${maxstddevpct}) 1 else 0" | bc) -eq 1 ]]; do
					if [[ $failures -gt 0 ]]; then
						echo "Restarting iteration $iteration ($count of $total_iterations)"
						log "Restarting iteration $iteration ($count of $total_iterations)"
					fi
					if [ "$postprocess_only" = "n" ]; then
						mkdir -p $iteration_dir
					else
						if [ ! -e $iteration_dir ]; then
							# if the iteration dir does not exist, look for a failed result directory or archive
							fail_nr=$failures
							((fail_nr++))
							fail_tag="-fail$fail_nr"
							failed_iteration_dir="$iteration_dir$fail_tag"
							if [ -e $failed_iteration_dir ]; then
								mv $failed_iteration_dir $iteration_dir || exit 1
							else
								failed_iteration_archive="$iteration_dir$fail_tag.tar.xz"
								if [ -e $failed_iteration_archive ]; then
									echo "using $failed_iteration_archive as $iteration_dir"
									tar -C $benchmark_run_dir -J -x -f $failed_iteration_archive || exit 1
									mv $failed_iteration_dir $iteration_dir || exit 1
								else
									echo "Could not find $iteration_dir, $failed_iteration_dir, or $failed_iteration_archive"
								fi
							fi
						fi
					fi
					if [ -e $iteration_dir ]; then
						iteration_failed=0
						# each attempt at a test config requires multiple samples to get stddev
						sample_failed=0
						for sample in `seq 1 $nr_samples`; do
							if [ "$job_mode" = "serial" ]; then
								dev_short_name="`basename $dev`"
								# easier to identify what job used what device when having 1 job per device
								iteration="$iteration-${dev_short_name}"
							fi
							benchmark_results_dir="$iteration_dir/sample$sample"
							benchmark_tools_dir="$benchmark_results_dir/tools-$tool_group"
							if [ "$postprocess_only" = "n" ]; then
								if [ -e $benchmark_results_dir ]; then
									/bin/rm -rf $benchmark_results_dir
								fi
								mkdir -p $benchmark_results_dir
								fio_job_file="$benchmark_results_dir/fio.job"
								fio_create_jobfile "$test_type" "$ioengine" "$block_size" "$iodepth" "$direct" "$sync" "$runtime" "$ramptime" "$file_size" "$rate_iops" "$histogram_interval_msec" "$dev" "$fio_job_file" "$numjobs"
								fio_run_job "$iteration" "$benchmark_results_dir" "$fio_job_file" "$clients"
							else
								# if we are only postprocessing, then we might have to untar an existing result
								pushd $iteration_dir >/dev/null
								if [ ! -e sample$sample ]; then
									if [ -e sample$sample.tar.xz ]; then
										tar Jxf sample$sample.tar.xz && /bin/rm sample$sample.tar.xz
									else
										echo "sample $sample missing.  There should be $nr_samples samples"
									fi
								fi
								popd >/dev/null
							fi
							debug_log "post-processing fio result"
							echo "$script_path/postprocess/$benchmark-postprocess \"$benchmark_results_dir\" \"$tool_label_pattern\" \"$tool_group\"" >"$benchmark_results_dir/$benchmark-postprocess.cmd"
							chmod +x "$benchmark_results_dir/$benchmark-postprocess.cmd"
							$benchmark_results_dir/$benchmark-postprocess.cmd
							rc=$?
							# if for any reason the benchmark postprocessing script fails, consider this a failure to get a sample
							if [ $rc -ne 0 ]; then
								debug_log "failed: $script_path/postprocess/$benchmark-postprocess $benchmark_results_dir $iteration $tool_group" 
								sample_failed=1
							fi
							if [ $sample_failed -eq 1 ]; then
								# we need all samples to be good, so bust out of testing samples now
								break
							fi
						done
					fi
					echo "$script_path/postprocess/process-iteration-samples \"$iteration_dir\" \"$primary_metric\" \"$maxstddevpct\" \"$failures\" \"$max_failures\" \"$tar_nonref_data\" \"$keep_failed_tool_data\"" >"$iteration_dir/process-iteration-samples.cmd"
					chmod +x "$iteration_dir/process-iteration-samples.cmd"
					$iteration_dir/process-iteration-samples.cmd
					fail=$?
					if [ $fail -ne  0 ]; then
						((failures++))
					fi
					if [ $fail -eq 0 -o $failures -ge $max_failures ]; then
						break
					fi
				done
			let count=$count+1 # now we can move to the next iteration
			done
		done
	done

	if [ ! -z "$client_file" ] ;then
		cp $client_file $benchmark_run_dir/fio-client.file
	fi
}

fio_process_options "$@"
fio_install

# pandas installed only on controller
if [ "$remote_only" = "n" ] ;then
	pandas_install
	sts=$?
	if [[ $sts != 0 ]] ;then
		echo "Could not install pandas package"
		exit $sts
	fi
fi
if [ "$install_only" = "y" ]; then
	exit 0
fi

mkdir -p $benchmark_run_dir
export benchmark config
pbench-collect-sysinfo --group=$tool_group --dir=$benchmark_run_dir --sysinfo=$sysinfo beg
pbench-metadata-log --group=$tool_group --dir=$benchmark_run_dir beg
fio_run_benchmark
pbench-metadata-log --group=$tool_group --dir=$benchmark_run_dir end
echo "$script_path/postprocess/generate-benchmark-summary \"$benchmark\" \"$orig_cmd\" \"$benchmark_run_dir\"" >"$benchmark_run_dir/generate-benchmark-summary.cmd"
chmod +x "$benchmark_run_dir/generate-benchmark-summary.cmd"
$script_path/postprocess/generate-benchmark-summary "$benchmark" "$orig_cmd" "$benchmark_run_dir"
pbench-collect-sysinfo --group=$tool_group --dir=$benchmark_run_dir  --sysinfo=$sysinfo end

rmdir $benchmark_run_dir/.running
