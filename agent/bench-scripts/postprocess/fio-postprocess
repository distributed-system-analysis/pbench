#!/usr/bin/perl

use strict;
use warnings;

# Check for an alternate tools library path for testing
my $_test_alt_tools_lib;
my $_test_alt_bench_lib;
BEGIN {
	my $_pbench_tspp_dir = $ENV{'pbench_tspp_dir'};
	$_test_alt_tools_lib=$ENV{_TEST_ALTERNATE_TOOLS_LIBRARY};
	if (not defined $_test_alt_tools_lib or not -d $_test_alt_tools_lib) {
		$_test_alt_tools_lib = "$_pbench_tspp_dir";
	}
	my $_pbench_bspp_dir = $ENV{'pbench_bspp_dir'};
	$_test_alt_bench_lib=$ENV{_TEST_ALTERNATE_BENCH_LIBRARY};
	if (not defined $_test_alt_bench_lib or not -d $_test_alt_bench_lib) {
		$_test_alt_bench_lib = "$_pbench_bspp_dir";
	}
}
use lib "$_test_alt_tools_lib";
use lib "$_test_alt_bench_lib";
no lib ".";
use GenData qw(gen_data);
use BenchPostprocess qw(value_exists trim_series get_label create_uid get_mean remove_timestamp get_timestamps write_influxdb_line_protocol get_cpubusy_series calc_ratio_series calc_sum_series div_series calc_aggregate_metrics calc_efficiency_metrics create_graph_hash get_json);
use File::Basename;
use Data::Dumper;
use List::Util('sum');
use JSON;
use Switch;

sub mean {
	if ( scalar @_ > 0 ) {
		return sum(@_)/@_;
	} else {
		return 0;
	}
}

my $script = basename($0);
my $dir = $ARGV[0];
my $tool_label_pattern = $ARGV[1];
my $tool_group = $ARGV[2];
my $benchmark_version = $ARGV[6];
my $benchmark_name = 'fio';
my %fio_sample;
my $timestamp_ms = 0;
my $prev_timestamp_ms = 0;
my $timestamp_ms_diff;
my $line;
my %avg;
my %total;
my $series_trim = 0;
my $primary_metric="iops_sec";



# %workload
#		   {Throughput|Latency|Resource|Efficiency}
#		   {Throughput}[iops_sec, 

my %workload;  # root hash for all data, contains hash refs to
		# %throughput, %latency, %resource, %efficiency
my %parameters;	# a hash of parameter-type:array-of-parameter-values

my @benchmark;	# each array element contains a hash with paramters
		# for this benchmark:
		# block-size: 256
		# test-type: randr

my %resource;	# a hash of resource-type:array-of-resource-values,

my @cpu_busy;	# each array element contains a hash with
		# hostname: hostname or IP
		# role: client, server, host, kvm-host, container-host, etc.
		# timeseries: a hash of timestamp:value key-pairs
my %efficiency;
my %latency;    # a hash of latency-type:array-of-latency-values,
		# for example $latency{usec[0..1]
my @clat;
my @slat;
my @lat;	# each array element contains a hash with:
	    	# hostname: <hostname or IP>
	    	# role: <client or server>
	    	# timeseries: a hash of timstamp:value elements

my %throughput; # a hash of throughput-type:array-of-throughput-values,
		# for example $throughput{MB_sec[0..1]
my @MB_sec;	# each array element contains a hash with:
	    	# hostname: <hostname or IP>
	    	# role: <client or server>
	    	# timeseries: a hash of timstamp:value key-pairs
my @iops_sec;	# each array element contains a hash with:
	    	# hostname: <hostname or IP>
	    	# role: <client or server>
	    	# timeseries: a hash of timstamp:value key-pair


# Get the tool data
# Define a set of tool directories which we want to use to report CPU and efficiency metrics
# Search for tool directories which match the $tool_label_pattern
my $this_tool_dir;
my %tool_ids;
my $tool_group_dir = "$dir/tools-$tool_group";
my $dh;
if (opendir($dh, $tool_group_dir)) {
	foreach $this_tool_dir (sort readdir($dh)) {
		if ($this_tool_dir =~ /^$tool_label_pattern/) {
			my $tool_dir_id = $this_tool_dir;
			$tool_dir_id =~ s/^$tool_label_pattern//;
			$this_tool_dir = $tool_group_dir . "/" . $this_tool_dir;
			$tool_ids{$this_tool_dir} = $tool_dir_id;
		}
	}
        closedir  $dh;
} else {
	print "$script: could not find any directories in $tool_group_dir which matched $tool_label_pattern\n";
}

foreach $this_tool_dir (sort keys %tool_ids) {
	my $res;
	my $this_tool_id = $tool_ids{$this_tool_dir};
	my $role = "host";
	my $url;
	my $hostname;
	($role, $hostname) = split(/:/,$this_tool_id);
	my @cpubusy_samples;
	$res = get_cpubusy_series($this_tool_dir, \@cpubusy_samples );
	if ( $res == 0 ) {
		my %this_cpubusy_dataset;
		my $description = "Total busy CPU usage, averaged over N seconds, where 1.0 = 1 logical CPU";
		my $mean = get_mean(\@cpubusy_samples);
		%this_cpubusy_dataset = ( get_label('uid_label') => create_uid('hostname_label'), get_label('description_label') => $description, get_label('role_label') => $role, get_label('hostname_label') => $hostname, get_label('value_label') => $mean, get_label('timeseries_label') => \@cpubusy_samples );
		push(@cpu_busy, \%this_cpubusy_dataset);
	}
}
if ( @cpu_busy ) {
	$resource{'cpu_busy'} = \@cpu_busy;
}

# get the fio benchmark parameters from the fio-result.txt (which is mostly json data)
my %benchmark_params;
my $fio_results_scalar = get_json($dir . "/fio-result.txt");
my %fio_results = %$fio_results_scalar;
my $job_num = 1;
my $num_jobs = 1;
for my $param (keys $fio_results{"global options"} ) {
	if (not $param =~/^write_\w+_log$/) {
		$benchmark_params{$param} = $fio_results{'global options'}{$param};
	}
}
if ($fio_results{"client_stats"}) {
	for my $client (@{ $fio_results{"client_stats"} }) {
		for my $param (keys $$client{"job options"} ) {
			if (not $param =~/^write_\w+_log$/) {
				$benchmark_params{$param} = $$client{"job options"}{$param};
			}
		}
	}
} elsif ($fio_results{"jobs"}) {
	for my $job (@{ $fio_results{"jobs"} }) {
		for my $param (keys $$job{"job options"} ) {
			if (not $param =~/^write_\w+_log$/) {
				if ($param =~/^numjobs$/) {
					$num_jobs = $benchmark_params{$param};
				} elsif ($param =~/^filename$/) {
					if ($job_num % 4 == 0) {
						if ($benchmark_params{$param}) {
							$benchmark_params{$param} = $benchmark_params{$param} . "," . $$job{"job options"}{$param};
						} else {
							$benchmark_params{$param} = $$job{"job options"}{$param};
						}
					}
				} else {
					$benchmark_params{$param} = $$job{"job options"}{$param};
				}
			}
		}
		$job_num++;
	}
	$benchmark_params{"total_jobs"} = $job_num - 1;
}
$benchmark_params{get_label('benchmark_name_label')} = $benchmark_name;
$benchmark_params{get_label('primary_metric_label')} = $primary_metric;
$benchmark_params{get_label('uid_label')} = create_uid('benchmark_name_label', 'controller_host_label');
push(@benchmark, \%benchmark_params);

# Load the data from fio output and create throughput & latency metrics.
# There can be several result files, for each client involved in this test
# and for each metric type.

my $nr_log_files=0;
my $clients_dh;
opendir($clients_dh, "$dir/clients") || die "$script: could not open directory $dir/clients: $!\n";
my $client_hostname_dir; 
my @client_hostname_dirs = grep(!/^\./, (sort readdir($clients_dh)));
closedir $clients_dh;
foreach $client_hostname_dir (@client_hostname_dirs) {
	# Process the log files (bw, lat, clat, etc)
	my $log_file;
	my $client_dh;
	opendir($client_dh, "$dir/clients/$client_hostname_dir") || die "$script: could not open directory $dir/clients/$client_hostname_dir $!\n";
	my @client_log_files = grep(/^.+\.log$/, (sort readdir($client_dh)));
	closedir $client_dh;
	foreach $log_file (@client_log_files) {
		# for each result file, build this:
		# # {
		# # "hostname": "perf104", <-where this workload was running
		# # "role": "client", <-where this information came from: workload client or server
		# # "samples" : {1407890808: 7.75, 1407890809: 7.77}  <-time series data from workload output
		# # "value" : "7.76" <-the average of the time series data
		# # },
		if ( $log_file =~ /^fio_(iops|lat|slat|clat)\.(\d+)\.log$/) {
			my $log_type = $1;
			my $job_id = $2;
			my $date_base = 1471365291000;
			my $role = "client";
			my $average;
			my @samples;
			my $description_label;
			my $this_metric;
			switch ($log_type) {
				case "iops"	{
							$description_label = "Number of I/O operations sent by client for a period of 1 second";
							$this_metric = \@iops_sec;
					}
				case "lat"	{
							$description_label = "Average total latency per I/O operation";
							$this_metric = \@lat;
					}
				case "clat"	{
							$description_label = "Average completion latency per I/O operation";
							$this_metric = \@clat;
					}
				case "slat"	{	$description_label = "Average submission latency per I/O operation";
							$this_metric = \@slat;
					}
			}
			open(IN_FILE, "$dir/clients/$client_hostname_dir/$log_file") || die "$script: could not open file $dir/clients/$client_hostname_dir/$log_file $!\n";
			while (<IN_FILE>) {
				$line = "$_";
				chomp($line);
				if ( $line =~  /(\d+),\s+(\d+),\s+(\d+),\s+(\d+)/ ) {
					#my $timestamp_ms = $1 + $date_base;
					my $timestamp_ms = $1;
					my $value = $2;
                                        my $rwtype = $3;
					my %sample = (get_label('date_label') => int $timestamp_ms, get_label('value_label') => int $value, get_label('rw_label') => int $rwtype);
                                        my $index = value_exists(get_label('date_label'), $timestamp_ms, \@samples);
                                        # duplicate timestamp *AND* duplicate rwtype
					if ($index >= 0 && $samples[$index]{get_label('rw_label')} == $rwtype) {
						printf "warning: timestamp already exists with this RW type, skipping this sample (file = %s timestamp = %d, value = %d, rwtype = %d)\n",
                                                    "$dir/clients/$client_hostname_dir/$log_file", $timestamp_ms, $value, $rwtype;
					} else {
						push(@samples, \%sample);
					}
				}
			}
			$nr_log_files++;
			close(IN_FILE);
			if ( (@samples) ) {
				trim_series(\@samples, $series_trim, $series_trim);
				my %this_dataset;
				my $mean = get_mean(\@samples);
				%this_dataset = ( 	get_label('role_label') => $role, get_label('client_hostname_label') => $client_hostname_dir . "-" . $job_id,
							get_label('value_label') => $mean, get_label('timeseries_label') => \@samples,
							get_label('uid_label') => create_uid('client_hostname_label')  );
				$this_dataset{get_label('description_label')} = $description_label;
				push(@$this_metric, \%this_dataset);
			}
		}
	}
	if ($nr_log_files == 0) {
		print "$script: could not find any result files to process, exiting\n";
		exit;
	}
}
# construct what we have so far in a master workload hash
if ( @iops_sec ) {
	$throughput{'iops_sec'} = \@iops_sec;
}
if ( @slat ) {
	$latency{'slat'} = \@slat;
}
if ( @clat ) {
	$latency{'clat'} = \@clat;
}
if ( @lat ) {
	$latency{'lat'} = \@lat;
}
if ( @benchmark ) {
	$parameters{'benchmark'} = \@benchmark;
}
if ( %throughput ) {
	$workload{'throughput'} = \%throughput;
}
if ( %latency ) {
	$workload{'latency'} = \%latency;
}
if ( %resource ) {
	$workload{'resource'} = \%resource;
}
if ( %parameters ) {
	$workload{'parameters'} = \%parameters;
}

calc_aggregate_metrics(\%workload);
calc_efficiency_metrics(\%workload);
		
# pbench graphing uses a specific hash heirarchy, where the dimensions of the hash are:
# {html-file}{html-graph}{graph-series}{timeseries-data}
# for example, an html page which has all of the iops_sec metrics graphed may look like:
# %throuhgput{'uperf-throughput'}{'iops-per-second'}{client:host1-to-server-host2}{$timestamp_ms}
#                                                 {client:host1-to-server-host3}{$timestamp_ms}
# if we wanted another graph for transactions per second graped in a different graph, but on the same html page, we would add:
# %throuhgput{'uperf-throughput'}{'transper-second'}{client:host1-to-server-host2}{$timestamp_ms}
#                                                   {client:host1-to-server-host3}{$timestamp_ms}
#
# So, for fio, we need to take parts of the data in %workload and transform it in to a new hash
# The %workload hash has much more information about the workload than needed for graphing, 
# and the timestamp data is stored in a different way.  So, we just need to do a minor 
# conversion, provided by BenchPostprocess.pm

my %graph;
create_graph_hash(\%graph, \%workload);
my %graph_threshold;
my %graph_type;
gen_data(\%graph, \%graph_type, \%graph_threshold, $dir, 1);

# write to JSON format file
my $json_file = $dir . "/result.json";
my $json_text   = to_json( \%workload, { ascii => 1, pretty => 1, canonical => 1 } );
open(JSON, ">$json_file") || die "$script: could not open file $json_file: $!\n";
print JSON $json_text;
close(JSON);

