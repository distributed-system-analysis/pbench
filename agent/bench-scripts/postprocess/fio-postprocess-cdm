#!/usr/bin/perl

use strict;
use warnings;
use File::Basename;
my $pbench_run_path;
my $pbench_lib_path;
BEGIN {
	$pbench_lib_path = `getconf.py pbench_install_dir pbench-agent`;
	chomp $pbench_lib_path;
	$pbench_lib_path .= "/lib";
}
use lib "$pbench_lib_path";
use JSON;
use Data::Dumper;
use PbenchCDM qw(create_run_doc create_config_osrelease_doc create_config_cpuinfo_doc create_config_netdevs_doc create_config_ethtool_doc create_config_base_doc get_hostname create_metric_sample_doc create_bench_iter_sample_period);
use PbenchBase qw(get_json_file put_json_file get_benchmark_names get_pbench_run_dir get_pbench_install_dir get_pbench_config_dir get_pbench_bench_config_dir get_benchmark_results_dir get_params remove_params remove_element);

printf "\@ARGV: %s\n", join(" ", @ARGV);

# todo: put stuff in the bench_iter_sample.json (CDM) doc
# - the primary metric
# - a list of all fio metrics this result has (this script generated)
#
# todo:
# - for each metric, create CDM doc(s), one per timeseries-sample
#
my $script_name = basename($0);
my $rundir = shift(@ARGV);
my $base_bench_dir = shift(@ARGV);
my $json_ref = get_json_file("bench-iter-sample.json");
my %bench_iter_sample = %$json_ref; # this is the CDM doc for this benchmark-iteration-sample
my $sample_id = $bench_iter_sample{"doc_id"}; # needs to be included in all metric-sample docs
my $run_id = $bench_iter_sample{"run_id"}; # needs to be included in all metric-sample docs
# create [at least one] benchmark period: a window of time during this benchmark, this one marked as "measurement",
# to indicate this period as the one the the UI/query tool computes a summary metric 
my %bench_iter_sample_period = create_bench_iter_sample_period($run_id, $sample_id, "measurement");
put_json_file(\%bench_iter_sample_period, $base_bench_dir . "/es/bench/bench-iter-sample-period" . $bench_iter_sample_period{"doc_id"} . ".json");
# the primary metric needs to match exactly one metric-type that gets created from the benchmark data
$bench_iter_sample{"primary_metric"} = "iops";
put_json_file(\%bench_iter_sample, $base_bench_dir . "/es/bench/bench-iter-sample-" . $bench_iter_sample{"doc_id"} . ".json");

# under ./clients/<hostname>, process the fio result files
opendir(my $clients_dh, "clients") || die "$script_name: could not open directory clients: $!\n";
my @client_hostname_dirs = grep(!/^\./, (sort readdir($clients_dh)));
closedir $clients_dh;
for my $client_hostname (@client_hostname_dirs) {
	mkdir("../../es/metrics");
	mkdir("../../es/metrics/" . $client_hostname);
	# first, try to process fio log files, and then if missing get the data from the fio-result.json.  Don't use both for the same metric
	my @log_metric_types = qw(bw clat iops lat slat); # all the possible metrics (except histogram logs) that can be timeseries data
	print "client: $client_hostname\n";
	opendir(my $client_dh, "clients/" . $client_hostname) || die "$script_name: could not open client directory: $!\n";
	my @log_files = grep(/fio_([a-z]+)\.(\d+)\.log$/, (sort readdir($client_dh)));
	closedir $client_dh;
	for my $log_file (@log_files) {
		if ($log_file =~ /fio_([a-z]+)\.(\d+)\.log$/) {
			my $metric_type = $1;
			my $job_id = $2;
			# process this timeseries data and remove this metric_type from processing in fio_result.json
			if (grep(/^$metric_type$/, @log_metric_types)) {
				# this allows us to know to skip looking for this in the fio_result.json
				remove_element(\@log_metric_types, $metric_type);
				open(my $log_fh, "clients/$client_hostname/$log_file") || die "$script_name: could not open file clients/$client_hostname/$log_file $!\n";
				while (<$log_fh>) {
					my $line = "$_";
					chomp($line);
					if ( $line =~  /(\d+),\s+(\d+),\s+(\d+),\s+(\d+)/ ) {
						my $timestamp_ms = $1;
						my $value = $2;
                                        	my $rwtype = $3; #todo: generate per-rwtype metrics
						my %metric_sample = create_metric_sample_doc(
									$run_id,
									"",		# benchmark-iteration doc id
									$sample_id,	# benchmark-iteration-sample doc id
									$bench_iter_sample_period{"doc_id"},	# benchmark-period doc id
									"throughput",	# metric-class
									$metric_type,	# metric-type
									$client_hostname,# hostname
									"fio",		# the source
									# the metric-instance name format
									"%source%-%type%-%client_hostname%",
									$value,		# the value of the metric
									$timestamp_ms	# the timestamp
									);
						put_json_file(\%metric_sample, "../../es/metrics/" .
										$client_hostname .
										"/metric-sample-" .
										$metric_sample{"doc_id"} .
										".json");
					}
				}
				close($log_fh);
			}
		}
	}
}
