#!/usr/bin/perl

# Author: Andrew Theurer
#
# usage: iostat-postprocess-cdm <tool_data_dir> <es_dir>
# tool_data_dir = the "tools-default" dir under ./interationX/sampleY
# es_dir = base directory for Elasticsearch documents
#
# The purpose of this script is to
# -create json docs suitable for importing into Elasticsearch
#  -one document per data-point (a specific metric at a specific time)
#  -documents written to $es_dir/metrics/$hostname/

use strict;
use warnings;
use File::Basename;
my $pbench_lib_path;
BEGIN {
	$pbench_lib_path = `getconf.py pbench_install_dir pbench-agent`;
	chomp $pbench_lib_path;
	$pbench_lib_path .= "/lib";
}
use lib "$pbench_lib_path";
use JSON;
use Data::Dumper;
use PbenchCDM qw(create_metric_desc_doc create_metric_data_doc);
use PbenchBase qw(get_json_file put_json_file get_benchmark_names get_pbench_run_dir get_pbench_install_dir get_pbench_config_dir get_pbench_bench_config_dir get_benchmark_results_dir get_params remove_params remove_element);

my $period_doc = shift;
my $es_dir = shift;
my $tool_dir = shift;
my $hostname = shift;
my $coder = JSON->new->ascii->canonical;
my $json_ref = get_json_file($period_doc);
my %period_doc = %$json_ref; # this is the CDM doc for the run

# there should be a directory for each host that have tools
my $timestamp;
my $timestamp_ms;
my $last_timestamp_ms;
open(IOSTAT_TXT, $tool_dir . "/iostat-stdout.txt") || die "could not find iostat-stdout.txt";
# A single ndjson file is used to store all values for this iostat output file
# Since there may be many iostat files (from different runs/iterations/samples/periods), the
# filename must have the period ID.
open(NDJSON_DESC_FH, ">" . $es_dir . "/metrics/" . $hostname .  "/metric_desc-" . $period_doc{"period"}{"id"} . "-iostat.ndjson");
open(NDJSON_DATA_FH, ">" . $es_dir . "/metrics/" . $hostname .  "/metric_data-" . $period_doc{"period"}{"id"} . "-iostat.ndjson");
my $count = 1;
my %metric_desc_ids;
while (my $line = <IOSTAT_TXT>) {
	chomp $line;
	# Each sample should start with a time stamp (the -t in iostat).
	# When we find this, update our timestamp for the hash.
	if ( $line =~ /^\d\d\/\d\d\/\d\d(\d\d)?\s\d\d:\d\d:\d\d(\s[AP]M)?/ ) {
		if ($timestamp_ms) {
			$last_timestamp_ms = $timestamp_ms;
		}
		$timestamp = `date --date="$line" +%s.%N`;
		# Elasticsearch requires the timestamp to be in milliseconds
		$timestamp_ms = $timestamp * 1000;
		if (!$last_timestamp_ms) {
			$last_timestamp_ms = $timestamp_ms;
		}
	}
	#     1    2    3     4     5      6      7     8     9      10      11     12       13       14    15    16
	#Device  r/s  w/s rMB/s wMB/s rrqm/s wrqm/s %rrqm %wrqm r_await w_await aqu-sz rareq-sz wareq-sz svctm %util
	#sdc    0.00 0.00  0.00  0.00   0.00   0.00  0.00  0.00    0.00    0.00   0.00     0.00     0.00  0.00  0.00
	#
	#                 1            2            3            4            5            6            7            8            9           10           11           12           13           14           15           16
	#                            r/s          w/s        rMB/s        wMB/s       rrqm/s       wrqm/s        %rrqm        %wrqm      r_await      w_await       aqu-sz     rareq-sz     wareq-sz        svctm        %util
	if ( $line =~ /(\S+)\s+(\d+\.\d+)\s+(\d+\.\d+)\s+(\d+\.\d+)\s+(\d+\.\d+)\s+(\d+\.\d+)\s+(\d+\.\d+)\s+(\d+\.\d+)\s+(\d+\.\d+)\s+(\d+\.\d+)\s+(\d+\.\d+)\s+(\d+\.\d+)\s+(\d+\.\d+)\s+(\d+\.\d+)\s+(\d+\.\d+)\s+(\d+\.\d+)(.*)/ ) {
		my $dev = $1;
		my %sample;
		$sample{"throughput"}{"blockdev_read_iops"} = $2;
		$sample{"throughput"}{"blockdev_write_iops"} = $3;
		$sample{"throughput"}{"blockdev_read_KB_sec"} = $4;
		$sample{"throughput"}{"blockdev_write_KB_sec"} = $5;
		$sample{"throughput"}{"blockdev_read_request_merges_sec"} = $6;
		$sample{"throughput"}{"blockdev_write_request_merges_sec"} = $7;
		# %rrqm - percent read rq merged -- ignored
		# %wrqm - percent write rq merged -- ignored
		$sample{"count"}{"blockdev_read_wait_msec"} = $10;
		$sample{"count"}{"blockdev_write_wait_msec"} = $11;
		$sample{"count"}{"blockdev_queue_size"} = $12;
		$sample{"count"}{"blockdev_read_request_size_KB"} = $13;
		$sample{"count"}{"blockdev_write_request_size_KB"} = $14;
		# svctm skipped, bogus stat
		$sample{"count"}{"blockdev_io_utilization_percent"} = $16;
		if (not exists $metric_desc_ids{$dev}) {
			for my $metric_class (keys %sample) {
				for my $metric_type (keys %{ $sample{$metric_class} }) {
					# Create the metric_desc doc only on the first occurrance of
					# the metric, and save the devce/class/type <-> metric id relationship
					my %metric_desc;
					%metric_desc = create_metric_desc_doc(
						\%period_doc,
						$metric_class,	# metric-class
						$metric_type,	# metric-type
						$hostname,# hostname
						"iostat",# the source
						"%source%-%type%-%host%-%device%");
					$metric_desc{"metric_desc"}{"device"} = $dev;
                               		printf NDJSON_DESC_FH "%s\n", '{ "index": {} }';
                               		printf NDJSON_DESC_FH "%s\n", $coder->encode(\%metric_desc);
					$metric_desc_ids{$dev}{$metric_class}{$metric_type} = $metric_desc{"metric_desc"}{"id"};
				}
			}
		}
		for my $metric_class (keys %sample) {
			for my $metric_type (keys %{ $sample{$metric_class} }) {
				my %metric_data = create_metric_data_doc($metric_desc_ids{$dev}{$metric_class}{$metric_type},
					$sample{$metric_class}{$metric_type},# the value of the metric
					$last_timestamp_ms + 1, $timestamp_ms);
                               	printf NDJSON_DATA_FH "%s\n", '{ "index": {} }';
                               	printf NDJSON_DATA_FH "%s\n", $coder->encode(\%metric_data);
			}
		}
	}
}
close(IOSTAT_TXT);
close(NDJSON_DESC_FH);
close(NDJSON_DATA_FH);
