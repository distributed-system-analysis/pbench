I0918 17:15:31.311613 1651 metrics.cc:160] found 1 GPUs supporting NVML metrics
I0918 17:15:31.317500 1651 metrics.cc:169]   GPU 0: TITAN RTX
I0918 17:15:31.317816 1651 server.cc:110] Initializing TensorRT Inference Server
I0918 17:15:31.352551 1651 server_status.cc:83] New status tracking for model 'graphdef_zero_1_float32'
I0918 17:15:31.352625 1651 model_repository_manager.cc:668] loading: graphdef_zero_1_float32:1
I0918 17:15:31.355203 1651 base_backend.cc:165] Creating instance graphdef_zero_1_float32_0_0_gpu0 on GPU 0 (7.5) using model.graphdef
2019-09-18 17:15:31.482412: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3599270000 Hz
2019-09-18 17:15:31.483079: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4ccc6a7c30 executing computations on platform Host. Devices:
2019-09-18 17:15:31.483100: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-18 17:15:31.483223: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-18 17:15:31.484676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:01:00.0
2019-09-18 17:15:31.484692: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-09-18 17:15:31.487362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-09-18 17:15:33.877168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-18 17:15:33.877218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-09-18 17:15:33.877226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-09-18 17:15:33.880986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22309 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5)
2019-09-18 17:15:33.882514: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4b91d68ab0 executing computations on platform CUDA. Devices:
2019-09-18 17:15:33.882533: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5
I0918 17:15:33.883725 1651 model_repository_manager.cc:810] successfully loaded 'graphdef_zero_1_float32' version 1
I0918 17:15:33.883772 1651 main.cc:417] Starting endpoints, 'inference:0' listening on
I0918 17:15:33.887056 1651 grpc_server.cc:1730] Started GRPCService at 0.0.0.0:8001
I0918 17:15:33.887103 1651 http_server.cc:1125] Starting HTTPService at 0.0.0.0:8000
I0918 17:15:33.929539 1651 http_server.cc:1139] Starting Metrics Service at 0.0.0.0:8002
I0918 17:15:52.338882 1651 main.cc:282] Interrupt signal (15) received.
I0918 17:15:52.338951 1651 server.cc:165] Waiting for in-flight inferences to complete.
I0918 17:15:52.338985 1651 model_repository_manager.cc:694] unloading: graphdef_zero_1_float32:1
I0918 17:15:52.339718 1651 model_repository_manager.cc:796] successfully unloaded 'graphdef_zero_1_float32' version 1
I0918 17:15:52.339753 1651 server.cc:180] Timeout 30: Found 0 live models and 0 in-flight requests
