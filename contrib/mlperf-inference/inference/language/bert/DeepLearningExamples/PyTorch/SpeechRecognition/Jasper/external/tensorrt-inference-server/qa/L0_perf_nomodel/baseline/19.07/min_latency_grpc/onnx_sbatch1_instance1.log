*** Measurement Settings ***
  Batch size: 1
  Measurement window: 5000 msec
  Latency limit: 300 msec
  Concurrency limit: 2 concurrent requests
  Stabilizing using p95 latency

Request concurrency: 1
  Pass [1] throughput: 4184 infer/sec. p95 latency: 293 usec
  Pass [2] throughput: 3635 infer/sec. p95 latency: 302 usec
  Pass [3] throughput: 3767 infer/sec. p95 latency: 309 usec
  Pass [4] throughput: 4524 infer/sec. p95 latency: 285 usec
  Pass [5] throughput: 4393 infer/sec. p95 latency: 278 usec
  Pass [6] throughput: 4580 infer/sec. p95 latency: 288 usec
  Client: 
    Request count: 22904
    Throughput: 4580 infer/sec
    p50 latency: 189 usec
    p90 latency: 275 usec
    p95 latency: 288 usec
    p99 latency: 342 usec
    Avg gRPC time: 194 usec (marshal 2 usec + response wait 187 usec + unmarshal 5 usec)
  Server: 
    Request count: 27829
    Avg request latency: 107 usec (overhead 6 usec + queue 11 usec + compute 90 usec)

Request concurrency: 2
  Pass [1] throughput: 7091 infer/sec. p95 latency: 370 usec
  Pass [2] throughput: 7139 infer/sec. p95 latency: 369 usec
  Pass [3] throughput: 7035 infer/sec. p95 latency: 379 usec
  Client: 
    Request count: 35178
    Throughput: 7035 infer/sec
    p50 latency: 263 usec
    p90 latency: 352 usec
    p95 latency: 379 usec
    p99 latency: 441 usec
    Avg gRPC time: 257 usec (marshal 3 usec + response wait 247 usec + unmarshal 7 usec)
  Server: 
    Request count: 42361
    Avg request latency: 117 usec (overhead 7 usec + queue 19 usec + compute 91 usec)

Inferences/Second vs. Client p95 Batch Latency
Concurrency: 1, 4580 infer/sec, latency 288 usec
Concurrency: 2, 7035 infer/sec, latency 379 usec
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  4283  100  4283    0     0   836k      0 --:--:-- --:--:-- --:--:--  836k
