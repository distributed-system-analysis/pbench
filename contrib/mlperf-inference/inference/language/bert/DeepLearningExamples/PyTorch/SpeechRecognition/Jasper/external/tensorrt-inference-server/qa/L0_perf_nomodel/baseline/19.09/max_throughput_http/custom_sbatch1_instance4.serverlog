I0918 17:20:59.251298 3106 metrics.cc:160] found 1 GPUs supporting NVML metrics
I0918 17:20:59.256900 3106 metrics.cc:169]   GPU 0: TITAN RTX
I0918 17:20:59.257139 3106 server.cc:110] Initializing TensorRT Inference Server
I0918 17:20:59.284934 3106 server_status.cc:83] New status tracking for model 'custom_zero_1_float32'
I0918 17:20:59.285000 3106 model_repository_manager.cc:668] loading: custom_zero_1_float32:1
I0918 17:20:59.286299 3106 custom_backend.cc:194] Creating instance custom_zero_1_float32_0_0_cpu on CPU using libcustom.so
I0918 17:20:59.287274 3106 custom_backend.cc:194] Creating instance custom_zero_1_float32_0_1_cpu on CPU using libcustom.so
I0918 17:20:59.287319 3106 custom_backend.cc:194] Creating instance custom_zero_1_float32_0_2_cpu on CPU using libcustom.so
I0918 17:20:59.287345 3106 custom_backend.cc:194] Creating instance custom_zero_1_float32_0_3_cpu on CPU using libcustom.so
I0918 17:20:59.377480 3106 model_repository_manager.cc:810] successfully loaded 'custom_zero_1_float32' version 1
I0918 17:20:59.377591 3106 main.cc:417] Starting endpoints, 'inference:0' listening on
I0918 17:20:59.379619 3106 grpc_server.cc:1730] Started GRPCService at 0.0.0.0:8001
I0918 17:20:59.379636 3106 http_server.cc:1125] Starting HTTPService at 0.0.0.0:8000
I0918 17:20:59.421535 3106 http_server.cc:1139] Starting Metrics Service at 0.0.0.0:8002
I0918 17:21:18.200225 3106 main.cc:282] Interrupt signal (15) received.
I0918 17:21:18.200258 3106 server.cc:165] Waiting for in-flight inferences to complete.
I0918 17:21:18.200271 3106 model_repository_manager.cc:694] unloading: custom_zero_1_float32:1
I0918 17:21:18.252642 3106 model_repository_manager.cc:796] successfully unloaded 'custom_zero_1_float32' version 1
I0918 17:21:18.252671 3106 server.cc:180] Timeout 30: Found 0 live models and 0 in-flight requests
