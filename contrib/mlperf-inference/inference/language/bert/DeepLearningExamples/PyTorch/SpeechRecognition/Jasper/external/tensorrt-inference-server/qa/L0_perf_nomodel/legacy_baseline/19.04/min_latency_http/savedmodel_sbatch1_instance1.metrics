# HELP exposer_bytes_transferred bytesTransferred to metrics services
# TYPE exposer_bytes_transferred counter
exposer_bytes_transferred 0.000000
# HELP exposer_total_scrapes Number of times metrics were scraped
# TYPE exposer_total_scrapes counter
exposer_total_scrapes 0.000000
# HELP exposer_request_latencies Latencies of serving scrape requests, in microseconds
# TYPE exposer_request_latencies summary
exposer_request_latencies_count 0
exposer_request_latencies_sum 0.000000
exposer_request_latencies{quantile="0.500000"} Nan
exposer_request_latencies{quantile="0.900000"} Nan
exposer_request_latencies{quantile="0.990000"} Nan
# HELP nv_inference_request_success Number of successful inference requests, all batch sizes
# TYPE nv_inference_request_success counter
nv_inference_request_success{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1"} 147179.000000
# HELP nv_inference_request_failure Number of failed inference requests, all batch sizes
# TYPE nv_inference_request_failure counter
# HELP nv_inference_count Number of inferences performed
# TYPE nv_inference_count counter
nv_inference_count{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1"} 147179.000000
# HELP nv_inference_exec_count Number of model executions performed
# TYPE nv_inference_exec_count counter
nv_inference_exec_count{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1"} 147179.000000
# HELP nv_inference_request_duration_us Cummulative inference request duration in microseconds
# TYPE nv_inference_request_duration_us counter
nv_inference_request_duration_us{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1"} 28809484.000000
# HELP nv_inference_compute_duration_us Cummulative inference compute duration in microseconds
# TYPE nv_inference_compute_duration_us counter
nv_inference_compute_duration_us{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1"} 23599721.000000
# HELP nv_inference_queue_duration_us Cummulative inference queuing duration in microseconds
# TYPE nv_inference_queue_duration_us counter
nv_inference_queue_duration_us{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1"} 1767805.000000
# TYPE nv_inference_load_ratio histogram
nv_inference_load_ratio_count{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1"} 147179
nv_inference_load_ratio_sum{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1"} 180338.777159
nv_inference_load_ratio_bucket{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1",le="1.050000"} 35
nv_inference_load_ratio_bucket{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1",le="1.100000"} 110
nv_inference_load_ratio_bucket{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1",le="1.250000"} 120251
nv_inference_load_ratio_bucket{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1",le="1.500000"} 144210
nv_inference_load_ratio_bucket{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1",le="2.000000"} 147015
nv_inference_load_ratio_bucket{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1",le="10.000000"} 147157
nv_inference_load_ratio_bucket{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1",le="50.000000"} 147178
nv_inference_load_ratio_bucket{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99",model="savedmodel_zero_1_float32",version="1",le="+Inf"} 147179
# HELP nv_gpu_utilization GPU utilization rate [0.0 - 1.0)
# TYPE nv_gpu_utilization gauge
nv_gpu_utilization{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99"} 0.010000
# HELP nv_gpu_memory_total_bytes GPU total memory, in bytes
# TYPE nv_gpu_memory_total_bytes gauge
nv_gpu_memory_total_bytes{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99"} 25365381120.000000
# HELP nv_gpu_memory_used_bytes GPU used memory, in bytes
# TYPE nv_gpu_memory_used_bytes gauge
nv_gpu_memory_used_bytes{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99"} 657260544.000000
# HELP nv_gpu_power_usage GPU power usage in watts
# TYPE nv_gpu_power_usage gauge
nv_gpu_power_usage{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99"} 69.508000
# HELP nv_gpu_power_limit GPU power management limit in watts
# TYPE nv_gpu_power_limit gauge
nv_gpu_power_limit{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99"} 280.000000
# HELP nv_energy_consumption GPU energy consumption in joules since the trtserver started
# TYPE nv_energy_consumption counter
nv_energy_consumption{gpu_uuid="GPU-afa8a63c-8c10-755e-256b-d987b765ba99"} 2483.587000
